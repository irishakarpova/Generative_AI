{"cells":[{"cell_type":"markdown","metadata":{"id":"U2VC_ZVQnfDG"},"source":["\n","<font size=10>Data Science and Business Analytics</font>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YCRLQ4s-nXhG"},"source":["# Book Review Analysis"]},{"cell_type":"markdown","metadata":{"id":"AE8-KrwBZfDV"},"source":["## Problem Statement\n"]},{"cell_type":"markdown","metadata":{"id":"za4BCdudZhUo"},"source":["### Business Context"]},{"cell_type":"markdown","metadata":{"id":"_NhER0I5Z5hC"},"source":["In the book industry, keeping readers satisfied is essential for the success of individual books and the reputation of publishers. A global book platform wants to better understand and improve how readers feel about the books it offers. The company knows that reader reviews are a valuable way to learn about the quality of the writing, the strength of the story, and how much readers enjoy the book overall."]},{"cell_type":"markdown","metadata":{"id":"ftZrhyLGaDiW"},"source":["### Problem Definition"]},{"cell_type":"markdown","metadata":{"id":"b3qjH2_xaaYi"},"source":["Even though there are plenty of reader reviews available, the company struggles to turn them into useful insights. Reading through large amounts of text by hand takes a lot of time and can’t be done efficiently at scale. The main challenges include:\n","\n","**Unstructured Data:** Reader reviews are written in casual written language, which makes it hard to quickly find important information about the book’s content, writing style, and reader reactions.\n","\n","**Large Volume of Reviews**: With thousands of books in many different genres, the platform collects a huge number of reviews. Going through all of them manually is not practical, so an automated approach is needed.\n","\n","**Understanding Reader Sentiment:** Figuring out whether a review is positive, negative, or neutral can be difficult. But this is important for learning what readers like or don`t like, improving book suggestions, and helping with marketing and publishing decisions."]},{"cell_type":"markdown","metadata":{"id":"KvhDvpz1afu1"},"source":["### Objective"]},{"cell_type":"markdown","metadata":{"id":"z7AM1Nc0aqKv"},"source":["The objective is to develop a sentiment analysis model leveraging a Large Language Model (LLM) to accurately classify reader sentiments—positive, negative, or neutral from unstructured book reviews. This model aims to enable scalable analysis of reader feedback, provide deeper insights into audience preferences, support data-driven editorial and marketing decisions, and ultimately enhance overall reader satisfaction on the platform."]},{"cell_type":"markdown","metadata":{"id":"ytzzr2FOntjn"},"source":["## Installing and Importing Libraries"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":114796,"status":"ok","timestamp":1751484091423,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"3WyoXoRvmRy9","outputId":"6eea4c2b-3825-4cb6-e4b3-eab8d6baf29d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.7/36.7 MB\u001b[0m \u001b[31m127.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m178.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m273.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m335.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m251.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m280.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# Installation for GPU llama-cpp-python\n","!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.2.45 --force-reinstall --no-cache-dir -q"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":4676,"status":"ok","timestamp":1751484156716,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"lFNUzbJjlJJo","outputId":"27d3555b-0c21-4ac0-c474-b61a650a09c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: huggingface_hub==0.33.1 in /usr/local/lib/python3.11/dist-packages (0.33.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.33.1) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.33.1) (2025.3.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.33.1) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.33.1) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.33.1) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.33.1) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.33.1) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.33.1) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.33.1) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.33.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.33.1) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.33.1) (2025.6.15)\n"]}],"source":["!pip install huggingface_hub==0.33.1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":851},"collapsed":true,"executionInfo":{"elapsed":15175,"status":"ok","timestamp":1751460663503,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"j8b6620e2zfF","outputId":"90708b6a-331a-4501-a692-2c65d0d2d206"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: numpy 2.3.1\n","Uninstalling numpy-2.3.1:\n","  Successfully uninstalled numpy-2.3.1\n","Found existing installation: scikit-learn 1.6.1\n","Uninstalling scikit-learn-1.6.1:\n","  Successfully uninstalled scikit-learn-1.6.1\n","Collecting numpy\n","  Downloading numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m266.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","libpysal 4.13.0 requires scikit-learn>=1.1, which is not installed.\n","librosa 0.11.0 requires scikit-learn>=1.1.0, which is not installed.\n","hdbscan 0.8.40 requires scikit-learn>=0.20, which is not installed.\n","umap-learn 0.5.7 requires scikit-learn>=0.22, which is not installed.\n","mlxtend 0.23.4 requires scikit-learn>=1.3.1, which is not installed.\n","tsfresh 0.21.0 requires scikit-learn>=0.22.0, which is not installed.\n","shap 0.48.0 requires scikit-learn, which is not installed.\n","sklearn-pandas 2.2.0 requires scikit-learn>=0.23.0, which is not installed.\n","fastai 2.7.19 requires scikit-learn, which is not installed.\n","imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, which is not installed.\n","pynndescent 0.5.13 requires scikit-learn>=0.18, which is not installed.\n","yellowbrick 1.5 requires scikit-learn>=1.0.0, which is not installed.\n","sentence-transformers 4.1.0 requires scikit-learn, which is not installed.\n","cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-2.3.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"81fb5cc8295543a28acbbe713ef4db5c","pip_warning":{"packages":["numpy"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Collecting scikit-learn\n","  Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n","Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.3.1)\n","Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-learn\n","^C\n"]}],"source":["!pip uninstall -y numpy\n","!pip uninstall -y scikit-learn\n","!pip install numpy --upgrade --no-cache-dir\n","!pip install scikit-learn --upgrade --no-cache-dir"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":4020,"status":"ok","timestamp":1751460669784,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"b2b53ea8","outputId":"577ff0f4-3f39-4418-a8dd-59d8ef08eb2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.7.0)\n","Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.3.1)\n","Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"]}],"source":["!pip install scikit-learn"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1111,"status":"ok","timestamp":1751484167460,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"OzB91jOilSv9"},"outputs":[],"source":["# Importing library for data manipulation\n","import pandas as pd\n","\n","# Function to download the model from the Hugging Face model hub\n","from huggingface_hub import hf_hub_download\n","\n","# Importing the Llama class from the llama_cpp module\n","from llama_cpp import Llama\n","\n","# Importing the json module\n","import json\n","\n","from tqdm.notebook import tqdm\n","\n","# Compare true vs predicted\n","# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"]},{"cell_type":"markdown","metadata":{"id":"Itg8C7IvnoyD"},"source":["## Import the dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1146,"status":"ok","timestamp":1751484171313,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"FlsNiKGjnoea","outputId":"ad0471cc-28a0-40a4-f7b8-306000fd23b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":292,"status":"ok","timestamp":1751484173573,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"Hx0IBAvbn5U5"},"outputs":[],"source":["df = pd.read_csv(\"/content/drive/MyDrive/Projects/Generative AI/g_reviews.csv\")"]},{"cell_type":"markdown","metadata":{"id":"wEXNvxfuoA8m"},"source":["## Data Overview"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1751484174655,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"TMJN0zxxRCow"},"outputs":[],"source":["data = df.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1751465869774,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"qnQ_CddvoIrD","outputId":"679ce666-f731-48c8-c3cc-961a9848d9fb"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"data\",\n  \"rows\": 1209,\n  \"fields\": [\n    {\n      \"column\": \"ReviewText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1209,\n        \"samples\": [\n          \"Review #102: Uninspiring and boring.\",\n          \"Review #433: Struggled to stay interested.\",\n          \"Review #310: Typical story, met expectations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"data"},"text/html":["\n","  <div id=\"df-7d4334ad-e052-43c8-bb59-885cdbfcaa09\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ReviewText</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Review #1: Highly disappointing read.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Review #2: A page-turner with a powerful message.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Review #3: A masterpiece of storytelling.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Review #4: Heartwarming and inspiring read.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Review #5: Neither good nor bad, just fine.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Review #6: Absolutely loved this book!</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Review #7: Overhyped and underwhelming.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Review #8: Some parts were slow, overall reada...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Review #9: Had its moments, but not remarkable.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Review #10: Neutral feelings, not very impactful.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Review #11: Plain narrative, suitable for casu...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Review #12: Struggled to stay interested.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Review #13: Had its moments, but not remarkable.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Review #14: Neither good nor bad, just fine.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Review #15: Terrible writing, couldn't finish it.</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d4334ad-e052-43c8-bb59-885cdbfcaa09')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7d4334ad-e052-43c8-bb59-885cdbfcaa09 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7d4334ad-e052-43c8-bb59-885cdbfcaa09');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-2b480eb1-9ff1-4c58-84d2-ad1709a21553\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b480eb1-9ff1-4c58-84d2-ad1709a21553')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-2b480eb1-9ff1-4c58-84d2-ad1709a21553 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                                           ReviewText  Sentiment\n","0               Review #1: Highly disappointing read.          0\n","1   Review #2: A page-turner with a powerful message.          2\n","2           Review #3: A masterpiece of storytelling.          2\n","3         Review #4: Heartwarming and inspiring read.          2\n","4         Review #5: Neither good nor bad, just fine.          1\n","5              Review #6: Absolutely loved this book!          2\n","6             Review #7: Overhyped and underwhelming.          0\n","7   Review #8: Some parts were slow, overall reada...          1\n","8     Review #9: Had its moments, but not remarkable.          1\n","9   Review #10: Neutral feelings, not very impactful.          1\n","10  Review #11: Plain narrative, suitable for casu...          1\n","11          Review #12: Struggled to stay interested.          0\n","12   Review #13: Had its moments, but not remarkable.          1\n","13       Review #14: Neither good nor bad, just fine.          1\n","14  Review #15: Terrible writing, couldn't finish it.          0"]},"execution_count":181,"metadata":{},"output_type":"execute_result"}],"source":["data.head(15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1751460751552,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"5dJmoO4_EKaZ","outputId":"aece8758-fa8e-4dab-b02a-b7bbdb1af4db"},"outputs":[{"data":{"text/plain":["(1209, 2)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["data.shape"]},{"cell_type":"markdown","metadata":{"id":"FdNTpI3toUc1"},"source":["**Observations**\n","\n","- Data has 1209 rows and 2 columns"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1751465883100,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"M8U37Tjiofzp","outputId":"14818035-b5f4-4250-b9a5-c3b579fae7d3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ReviewText</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Sentiment</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"],"text/plain":["ReviewText    0\n","Sentiment     0\n","dtype: int64"]},"execution_count":182,"metadata":{},"output_type":"execute_result"}],"source":["# checking for missing values\n","data.isnull().sum()"]},{"cell_type":"markdown","metadata":{"id":"VGc5Vau5ojPe"},"source":["**Observations**\n","\n","- There are no missing values in the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7PSQlvldpWOV"},"outputs":[],"source":["# Count the number of reviews per sentiment\n","sentiment_counts = data['Sentiment'].value_counts().sort_index()\n","\n","# Map sentiment labels for readability\n","sentiment_labels = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n","sentiment_counts.index = sentiment_counts.index.map(sentiment_labels)"]},{"cell_type":"markdown","metadata":{"id":"tp6-ecSOpoDy"},"source":["**Observation:**\n","\n","1. The dataset is fairly balanced across all three sentiment categories:\n","\n","- Positive: 33.5%\n","- Neutral: 34.2%\n","- Negative: 32.3%\n","\n","2. It indicates that the dataset includes a good variety of reader opinions, which can help build a more generalizable model."]},{"cell_type":"markdown","metadata":{"id":"NqzMDWfgD_hS"},"source":["### Utility function"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1751484518910,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"d3wZUybhD9ZD"},"outputs":[],"source":["# defining a function to parse the JSON output from the model\n","def extract_json_data(json_str):\n","    try:\n","        # Find the indices of the opening and closing curly braces\n","        json_start = json_str.find('{')\n","        json_end = json_str.rfind('}')\n","\n","        if json_start != -1 and json_end != -1:\n","            extracted_sentiment = json_str[json_start:json_end + 1]  # Extract the JSON object\n","            data_dict = json.loads(extracted_sentiment)\n","            return data_dict\n","        else:\n","            print(f\"Warning: JSON object not found in response: {json_str}\")\n","            return {}\n","    except json.JSONDecodeError as e:\n","        print(f\"Error parsing JSON: {e}\")\n","        return {}"]},{"cell_type":"markdown","metadata":{"id":"HFTXXigKn8dj"},"source":["## Llama Model Building"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1751484202907,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"OCa5hssPn_Da"},"outputs":[],"source":["#This is Hugging Face model repository created by TheBloke, who publishes quantized GGUF-format models for use with llama.cpp\n","model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n","model_basename = \"llama-2-13b-chat.Q5_K_M.gguf\""]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176,"referenced_widgets":["414889a1ed9d4f55becaffc3812632f8","9b675d6d6c9048e8b800e3cf0a8e3b98","db8d9f378da847d684e804d801167db9","02f0b9e3b5cf432eb26fd2f51eed4106","d016de8a4e8c447db27b4f69e2c0799c","3bdc76bea1aa4281b52c06b2cf1aa74f","88a11a6743e14d46bf1aa16977d362fe","144e7aedb94746caa47d3c6c5374a7bc","e1ee68eb5604457f897d5c13b98ad781","8845617b8d5b47cebd108fa9ef0b03a0","236a89f46aab412da85afeee1e77c400"]},"collapsed":true,"executionInfo":{"elapsed":40186,"status":"ok","timestamp":1751484244362,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"-eVyGeNHpbzK","outputId":"84b015c4-7096-403c-d256-a05fb82ed507"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["llama-2-13b-chat.Q5_K_M.gguf:   0%|          | 0.00/9.23G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"414889a1ed9d4f55becaffc3812632f8"}},"metadata":{}}],"source":["# The filename parameter specifies the name of the file to download\n","model_path = hf_hub_download(\n","    repo_id=model_name_or_path,\n","    filename=model_basename\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":2885,"status":"ok","timestamp":1751484249579,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"9UsucVv7pMGb","outputId":"99d3376b-9f6f-4390-f1d2-1d9703087bfe"},"outputs":[{"output_type":"stream","name":"stderr","text":["llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_M.gguf (version GGUF V2)\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n","llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n","llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n","llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n","llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n","llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n","llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n","llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n","llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n","llama_model_loader: - kv  10:                          general.file_type u32              = 17\n","llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n","llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n","llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n","llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n","llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n","llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n","llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n","llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:   81 tensors\n","llama_model_loader: - type q5_K:  241 tensors\n","llama_model_loader: - type q6_K:   41 tensors\n","llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n","llm_load_print_meta: format           = GGUF V2\n","llm_load_print_meta: arch             = llama\n","llm_load_print_meta: vocab type       = SPM\n","llm_load_print_meta: n_vocab          = 32000\n","llm_load_print_meta: n_merges         = 0\n","llm_load_print_meta: n_ctx_train      = 4096\n","llm_load_print_meta: n_embd           = 5120\n","llm_load_print_meta: n_head           = 40\n","llm_load_print_meta: n_head_kv        = 40\n","llm_load_print_meta: n_layer          = 40\n","llm_load_print_meta: n_rot            = 128\n","llm_load_print_meta: n_embd_head_k    = 128\n","llm_load_print_meta: n_embd_head_v    = 128\n","llm_load_print_meta: n_gqa            = 1\n","llm_load_print_meta: n_embd_k_gqa     = 5120\n","llm_load_print_meta: n_embd_v_gqa     = 5120\n","llm_load_print_meta: f_norm_eps       = 0.0e+00\n","llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n","llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n","llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n","llm_load_print_meta: n_ff             = 13824\n","llm_load_print_meta: n_expert         = 0\n","llm_load_print_meta: n_expert_used    = 0\n","llm_load_print_meta: rope scaling     = linear\n","llm_load_print_meta: freq_base_train  = 10000.0\n","llm_load_print_meta: freq_scale_train = 1\n","llm_load_print_meta: n_yarn_orig_ctx  = 4096\n","llm_load_print_meta: rope_finetuned   = unknown\n","llm_load_print_meta: model type       = 13B\n","llm_load_print_meta: model ftype      = Q5_K - Medium\n","llm_load_print_meta: model params     = 13.02 B\n","llm_load_print_meta: model size       = 8.60 GiB (5.67 BPW) \n","llm_load_print_meta: general.name     = LLaMA v2\n","llm_load_print_meta: BOS token        = 1 '<s>'\n","llm_load_print_meta: EOS token        = 2 '</s>'\n","llm_load_print_meta: UNK token        = 0 '<unk>'\n","llm_load_print_meta: LF token         = 13 '<0x0A>'\n","llm_load_tensors: ggml ctx size =    0.28 MiB\n","llm_load_tensors: offloading 40 repeating layers to GPU\n","llm_load_tensors: offloaded 40/41 layers to GPU\n","llm_load_tensors:        CPU buffer size =  8801.63 MiB\n","llm_load_tensors:      CUDA0 buffer size =  8566.02 MiB\n","....................................................................................................\n","llama_new_context_with_model: n_ctx      = 4096\n","llama_new_context_with_model: freq_base  = 10000.0\n","llama_new_context_with_model: freq_scale = 1\n","llama_kv_cache_init:      CUDA0 KV buffer size =  3200.00 MiB\n","llama_new_context_with_model: KV self size  = 3200.00 MiB, K (f16): 1600.00 MiB, V (f16): 1600.00 MiB\n","llama_new_context_with_model:  CUDA_Host input buffer size   =    19.04 MiB\n","llama_new_context_with_model:      CUDA0 compute buffer size =   368.02 MiB\n","llama_new_context_with_model:  CUDA_Host compute buffer size =    82.50 MiB\n","llama_new_context_with_model: graph splits (measure): 4\n","AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n","Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\n"]}],"source":["# I use T4 GPU GPU RAM 15.0 GB that is why n_gpu_layers=40\n","llm = Llama(\n","    model_path=model_path,\n","    n_ctx=4096,\n","    n_threads=8,\n","    n_gpu_layers=40,\n","    f16_kv=True,\n","    use_mmap=True,\n","    use_mlock=False\n",")"]},{"cell_type":"markdown","metadata":{"id":"z4rE0TFCwqoM"},"source":["### Model Response Parameters"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":41,"status":"ok","timestamp":1751484253000,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"ClVpI6hHwvb0"},"outputs":[],"source":["def generate_llama_response(instruction, review):\n","    prompt = f\"\"\"[INST] <<SYS>>\n","{instruction.strip()}\n","<</SYS>>\n","\n","{review.strip()}\n","[/INST]\"\"\"\n","\n","    response = llm(\n","        prompt=prompt,\n","        max_tokens=512,\n","        temperature=0,\n","        top_p=1.0,\n","        top_k=0,\n","        repeat_penalty=1.0,\n","        echo=False,\n","        seed=42,\n","    )\n","\n","    return response[\"choices\"][0][\"text\"].strip()"]},{"cell_type":"markdown","metadata":{"id":"oxi_DMsyxBjn"},"source":["### 1. Sentiment Analysis (Llama)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V8ITsUKvxH4I"},"outputs":[],"source":["# creating a copy of the data\n","# data_1 = data.copy()\n","data_1 = data.iloc[:100].copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1751461760807,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"tiefmulpOy6C","outputId":"f2984e3e-2b34-4968-d1f4-0aec13320d28"},"outputs":[{"data":{"text/plain":["(100, 2)"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["data_1.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yseq6ag5Olgf"},"outputs":[],"source":["#Clean review text\n","data_1[\"CleanedReview\"] = data_1[\"ReviewText\"].str.replace(r\"^Review\\s+#\\d+:\\s*\", \"\", regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fe9XqMQdxKD6"},"outputs":[],"source":["# defining the instructions for the model\n","instruction = \"\"\"\n","You are a sentiment classifier.\n","\n","Read the following book review and respond with exactly one word:\n","Positive, Neutral, or Negative.\n","\n","Do not include any greetings, explanations, or extra text.\n","Only respond with one of the three words — exactly as written.\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["854a6eb0db714098aa8c65308cdcc1d1","9ea642521b7a49ca820de04a15ff9e0e","12e4d6aa1b33464888f3b57a9c2a7e29","3a51a2c2a0a64bd39a4e847a92430e4a","7ce5b44adac04ee2863d95d837582a22","02548326fd58424a923cc93cfa4a038d","49babd6316354bceb80b152e35175b29","91a2220adbe44d6ca34e3e10d27437c1","96acdf3d3c944048ba3b4d7d3f27440e","73c85a9156004ca0a5ece55f67c8e600","2cacb8f42fef414ca176e67d3a0c96f2"]},"executionInfo":{"elapsed":85972,"status":"ok","timestamp":1751466004670,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"BLW-o_nDDD_g","outputId":"55909403-8b00-4e74-bae4-aa5ba7444766"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"854a6eb0db714098aa8c65308cdcc1d1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23668.64 tokens per second)\n","llama_print_timings: prompt eval time =     481.38 ms /    81 tokens (    5.94 ms per token,   168.27 tokens per second)\n","llama_print_timings:        eval time =     253.45 ms /     3 runs   (   84.48 ms per token,    11.84 tokens per second)\n","llama_print_timings:       total time =     747.21 ms /    84 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.19 ms /     4 runs   (    0.05 ms per token, 21052.63 tokens per second)\n","llama_print_timings: prompt eval time =     420.70 ms /    15 tokens (   28.05 ms per token,    35.65 tokens per second)\n","llama_print_timings:        eval time =     176.66 ms /     3 runs   (   58.89 ms per token,    16.98 tokens per second)\n","llama_print_timings:       total time =     609.22 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.16 ms /     4 runs   (    0.04 ms per token, 24539.88 tokens per second)\n","llama_print_timings: prompt eval time =     433.03 ms /    13 tokens (   33.31 ms per token,    30.02 tokens per second)\n","llama_print_timings:        eval time =     178.02 ms /     3 runs   (   59.34 ms per token,    16.85 tokens per second)\n","llama_print_timings:       total time =     622.02 ms /    16 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.18 ms /     4 runs   (    0.05 ms per token, 21739.13 tokens per second)\n","llama_print_timings: prompt eval time =     432.41 ms /    15 tokens (   28.83 ms per token,    34.69 tokens per second)\n","llama_print_timings:        eval time =     177.56 ms /     3 runs   (   59.19 ms per token,    16.90 tokens per second)\n","llama_print_timings:       total time =     621.51 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 24390.24 tokens per second)\n","llama_print_timings: prompt eval time =     430.24 ms /    14 tokens (   30.73 ms per token,    32.54 tokens per second)\n","llama_print_timings:        eval time =     255.55 ms /     4 runs   (   63.89 ms per token,    15.65 tokens per second)\n","llama_print_timings:       total time =     699.14 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23391.81 tokens per second)\n","llama_print_timings: prompt eval time =     333.39 ms /    12 tokens (   27.78 ms per token,    35.99 tokens per second)\n","llama_print_timings:        eval time =     178.77 ms /     3 runs   (   59.59 ms per token,    16.78 tokens per second)\n","llama_print_timings:       total time =     523.70 ms /    15 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.16 ms /     4 runs   (    0.04 ms per token, 24390.24 tokens per second)\n","llama_print_timings: prompt eval time =     438.23 ms /    15 tokens (   29.22 ms per token,    34.23 tokens per second)\n","llama_print_timings:        eval time =     172.18 ms /     3 runs   (   57.39 ms per token,    17.42 tokens per second)\n","llama_print_timings:       total time =     621.61 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.22 ms /     5 runs   (    0.04 ms per token, 22624.43 tokens per second)\n","llama_print_timings: prompt eval time =     435.78 ms /    13 tokens (   33.52 ms per token,    29.83 tokens per second)\n","llama_print_timings:        eval time =     239.03 ms /     4 runs   (   59.76 ms per token,    16.73 tokens per second)\n","llama_print_timings:       total time =     688.54 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.23 ms /     5 runs   (    0.05 ms per token, 21367.52 tokens per second)\n","llama_print_timings: prompt eval time =     436.98 ms /    14 tokens (   31.21 ms per token,    32.04 tokens per second)\n","llama_print_timings:        eval time =     259.08 ms /     4 runs   (   64.77 ms per token,    15.44 tokens per second)\n","llama_print_timings:       total time =     709.81 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.22 ms /     5 runs   (    0.04 ms per token, 22831.05 tokens per second)\n","llama_print_timings: prompt eval time =     430.44 ms /    15 tokens (   28.70 ms per token,    34.85 tokens per second)\n","llama_print_timings:        eval time =     251.65 ms /     4 runs   (   62.91 ms per token,    15.90 tokens per second)\n","llama_print_timings:       total time =     696.31 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       2.18 ms /    51 runs   (    0.04 ms per token, 23448.28 tokens per second)\n","llama_print_timings: prompt eval time =     442.12 ms /    16 tokens (   27.63 ms per token,    36.19 tokens per second)\n","llama_print_timings:        eval time =    3517.66 ms /    50 runs   (   70.35 ms per token,    14.21 tokens per second)\n","llama_print_timings:       total time =    4098.41 ms /    66 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.18 ms /     4 runs   (    0.04 ms per token, 22222.22 tokens per second)\n","llama_print_timings: prompt eval time =     379.16 ms /    12 tokens (   31.60 ms per token,    31.65 tokens per second)\n","llama_print_timings:        eval time =     365.57 ms /     3 runs   (  121.86 ms per token,     8.21 tokens per second)\n","llama_print_timings:       total time =     757.01 ms /    15 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 23923.44 tokens per second)\n","llama_print_timings: prompt eval time =     455.06 ms /    14 tokens (   32.50 ms per token,    30.77 tokens per second)\n","llama_print_timings:        eval time =     498.13 ms /     4 runs   (  124.53 ms per token,     8.03 tokens per second)\n","llama_print_timings:       total time =     967.09 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 23474.18 tokens per second)\n","llama_print_timings: prompt eval time =     452.01 ms /    14 tokens (   32.29 ms per token,    30.97 tokens per second)\n","llama_print_timings:        eval time =     308.95 ms /     4 runs   (   77.24 ms per token,    12.95 tokens per second)\n","llama_print_timings:       total time =     775.97 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.18 ms /     4 runs   (    0.04 ms per token, 22727.27 tokens per second)\n","llama_print_timings: prompt eval time =     445.38 ms /    16 tokens (   27.84 ms per token,    35.92 tokens per second)\n","llama_print_timings:        eval time =     202.80 ms /     3 runs   (   67.60 ms per token,    14.79 tokens per second)\n","llama_print_timings:       total time =     658.77 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       2.17 ms /    51 runs   (    0.04 ms per token, 23480.66 tokens per second)\n","llama_print_timings: prompt eval time =     470.59 ms /    16 tokens (   29.41 ms per token,    34.00 tokens per second)\n","llama_print_timings:        eval time =    3825.80 ms /    50 runs   (   76.52 ms per token,    13.07 tokens per second)\n","llama_print_timings:       total time =    4434.76 ms /    66 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.23 ms /     5 runs   (    0.05 ms per token, 21929.82 tokens per second)\n","llama_print_timings: prompt eval time =     445.59 ms /    13 tokens (   34.28 ms per token,    29.17 tokens per second)\n","llama_print_timings:        eval time =     283.48 ms /     4 runs   (   70.87 ms per token,    14.11 tokens per second)\n","llama_print_timings:       total time =     742.92 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.26 ms /     6 runs   (    0.04 ms per token, 22727.27 tokens per second)\n","llama_print_timings: prompt eval time =     468.56 ms /    14 tokens (   33.47 ms per token,    29.88 tokens per second)\n","llama_print_timings:        eval time =     375.98 ms /     5 runs   (   75.20 ms per token,    13.30 tokens per second)\n","llama_print_timings:       total time =     861.07 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 23696.68 tokens per second)\n","llama_print_timings: prompt eval time =     459.32 ms /    13 tokens (   35.33 ms per token,    28.30 tokens per second)\n","llama_print_timings:        eval time =     280.19 ms /     4 runs   (   70.05 ms per token,    14.28 tokens per second)\n","llama_print_timings:       total time =     752.98 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.18 ms /     4 runs   (    0.05 ms per token, 21978.02 tokens per second)\n","llama_print_timings: prompt eval time =     342.15 ms /    11 tokens (   31.10 ms per token,    32.15 tokens per second)\n","llama_print_timings:        eval time =     199.33 ms /     3 runs   (   66.44 ms per token,    15.05 tokens per second)\n","llama_print_timings:       total time =     552.41 ms /    14 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.19 ms /     4 runs   (    0.05 ms per token, 20618.56 tokens per second)\n","llama_print_timings: prompt eval time =     358.47 ms /    12 tokens (   29.87 ms per token,    33.48 tokens per second)\n","llama_print_timings:        eval time =     200.30 ms /     3 runs   (   66.77 ms per token,    14.98 tokens per second)\n","llama_print_timings:       total time =     570.35 ms /    15 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.25 ms /     5 runs   (    0.05 ms per token, 19762.85 tokens per second)\n","llama_print_timings: prompt eval time =     470.28 ms /    15 tokens (   31.35 ms per token,    31.90 tokens per second)\n","llama_print_timings:        eval time =     277.12 ms /     4 runs   (   69.28 ms per token,    14.43 tokens per second)\n","llama_print_timings:       total time =     761.84 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 24242.42 tokens per second)\n","llama_print_timings: prompt eval time =     455.92 ms /    14 tokens (   32.57 ms per token,    30.71 tokens per second)\n","llama_print_timings:        eval time =     246.78 ms /     3 runs   (   82.26 ms per token,    12.16 tokens per second)\n","llama_print_timings:       total time =     714.53 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.23 ms /     5 runs   (    0.05 ms per token, 22123.89 tokens per second)\n","llama_print_timings: prompt eval time =     476.70 ms /    15 tokens (   31.78 ms per token,    31.47 tokens per second)\n","llama_print_timings:        eval time =     393.65 ms /     4 runs   (   98.41 ms per token,    10.16 tokens per second)\n","llama_print_timings:       total time =     885.48 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.16 ms /     4 runs   (    0.04 ms per token, 24390.24 tokens per second)\n","llama_print_timings: prompt eval time =     466.32 ms /    13 tokens (   35.87 ms per token,    27.88 tokens per second)\n","llama_print_timings:        eval time =     234.77 ms /     3 runs   (   78.26 ms per token,    12.78 tokens per second)\n","llama_print_timings:       total time =     712.91 ms /    16 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23391.81 tokens per second)\n","llama_print_timings: prompt eval time =     451.02 ms /    15 tokens (   30.07 ms per token,    33.26 tokens per second)\n","llama_print_timings:        eval time =     200.41 ms /     3 runs   (   66.80 ms per token,    14.97 tokens per second)\n","llama_print_timings:       total time =     662.78 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23809.52 tokens per second)\n","llama_print_timings: prompt eval time =     479.61 ms /    15 tokens (   31.97 ms per token,    31.28 tokens per second)\n","llama_print_timings:        eval time =     217.31 ms /     3 runs   (   72.44 ms per token,    13.81 tokens per second)\n","llama_print_timings:       total time =     707.78 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.16 ms /     4 runs   (    0.04 ms per token, 24539.88 tokens per second)\n","llama_print_timings: prompt eval time =     453.10 ms /    13 tokens (   34.85 ms per token,    28.69 tokens per second)\n","llama_print_timings:        eval time =     212.07 ms /     3 runs   (   70.69 ms per token,    14.15 tokens per second)\n","llama_print_timings:       total time =     676.04 ms /    16 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 24242.42 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =     309.57 ms /     4 runs   (   77.39 ms per token,    12.92 tokens per second)\n","llama_print_timings:       total time =     319.22 ms /     5 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.22 ms /     5 runs   (    0.04 ms per token, 22831.05 tokens per second)\n","llama_print_timings: prompt eval time =     462.44 ms /    13 tokens (   35.57 ms per token,    28.11 tokens per second)\n","llama_print_timings:        eval time =     268.24 ms /     4 runs   (   67.06 ms per token,    14.91 tokens per second)\n","llama_print_timings:       total time =     744.32 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23529.41 tokens per second)\n","llama_print_timings: prompt eval time =     593.87 ms /    18 tokens (   32.99 ms per token,    30.31 tokens per second)\n","llama_print_timings:        eval time =     204.38 ms /     3 runs   (   68.13 ms per token,    14.68 tokens per second)\n","llama_print_timings:       total time =     809.92 ms /    21 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 23364.49 tokens per second)\n","llama_print_timings: prompt eval time =     466.95 ms /    14 tokens (   33.35 ms per token,    29.98 tokens per second)\n","llama_print_timings:        eval time =     325.28 ms /     4 runs   (   81.32 ms per token,    12.30 tokens per second)\n","llama_print_timings:       total time =     806.07 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 23364.49 tokens per second)\n","llama_print_timings: prompt eval time =     453.33 ms /    14 tokens (   32.38 ms per token,    30.88 tokens per second)\n","llama_print_timings:        eval time =     272.67 ms /     4 runs   (   68.17 ms per token,    14.67 tokens per second)\n","llama_print_timings:       total time =     739.54 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.25 ms /     5 runs   (    0.05 ms per token, 20325.20 tokens per second)\n","llama_print_timings: prompt eval time =     478.24 ms /    14 tokens (   34.16 ms per token,    29.27 tokens per second)\n","llama_print_timings:        eval time =     276.25 ms /     4 runs   (   69.06 ms per token,    14.48 tokens per second)\n","llama_print_timings:       total time =     767.88 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.18 ms /     4 runs   (    0.04 ms per token, 22346.37 tokens per second)\n","llama_print_timings: prompt eval time =     340.56 ms /    12 tokens (   28.38 ms per token,    35.24 tokens per second)\n","llama_print_timings:        eval time =     203.53 ms /     3 runs   (   67.84 ms per token,    14.74 tokens per second)\n","llama_print_timings:       total time =     555.69 ms /    15 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.16 ms /     4 runs   (    0.04 ms per token, 24390.24 tokens per second)\n","llama_print_timings: prompt eval time =     477.71 ms /    15 tokens (   31.85 ms per token,    31.40 tokens per second)\n","llama_print_timings:        eval time =     203.76 ms /     3 runs   (   67.92 ms per token,    14.72 tokens per second)\n","llama_print_timings:       total time =     692.84 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 20000.00 tokens per second)\n","llama_print_timings: prompt eval time =     446.00 ms /    13 tokens (   34.31 ms per token,    29.15 tokens per second)\n","llama_print_timings:        eval time =     198.26 ms /     3 runs   (   66.09 ms per token,    15.13 tokens per second)\n","llama_print_timings:       total time =     654.93 ms /    16 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23952.10 tokens per second)\n","llama_print_timings: prompt eval time =     364.52 ms /    12 tokens (   30.38 ms per token,    32.92 tokens per second)\n","llama_print_timings:        eval time =     215.88 ms /     3 runs   (   71.96 ms per token,    13.90 tokens per second)\n","llama_print_timings:       total time =     591.33 ms /    15 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 24154.59 tokens per second)\n","llama_print_timings: prompt eval time =     451.41 ms /    15 tokens (   30.09 ms per token,    33.23 tokens per second)\n","llama_print_timings:        eval time =     257.34 ms /     4 runs   (   64.34 ms per token,    15.54 tokens per second)\n","llama_print_timings:       total time =     722.34 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 24096.39 tokens per second)\n","llama_print_timings: prompt eval time =     461.26 ms /    15 tokens (   30.75 ms per token,    32.52 tokens per second)\n","llama_print_timings:        eval time =     215.98 ms /     3 runs   (   71.99 ms per token,    13.89 tokens per second)\n","llama_print_timings:       total time =     687.83 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.16 ms /     4 runs   (    0.04 ms per token, 24691.36 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =     345.48 ms /     4 runs   (   86.37 ms per token,    11.58 tokens per second)\n","llama_print_timings:       total time =     356.74 ms /     5 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.26 ms /     6 runs   (    0.04 ms per token, 22813.69 tokens per second)\n","llama_print_timings: prompt eval time =     458.14 ms /    14 tokens (   32.72 ms per token,    30.56 tokens per second)\n","llama_print_timings:        eval time =     500.19 ms /     5 runs   (  100.04 ms per token,    10.00 tokens per second)\n","llama_print_timings:       total time =     976.51 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.18 ms /     4 runs   (    0.04 ms per token, 22346.37 tokens per second)\n","llama_print_timings: prompt eval time =     457.49 ms /    14 tokens (   32.68 ms per token,    30.60 tokens per second)\n","llama_print_timings:        eval time =     201.25 ms /     3 runs   (   67.08 ms per token,    14.91 tokens per second)\n","llama_print_timings:       total time =     671.44 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23255.81 tokens per second)\n","llama_print_timings: prompt eval time =     327.27 ms /    10 tokens (   32.73 ms per token,    30.56 tokens per second)\n","llama_print_timings:        eval time =     174.50 ms /     3 runs   (   58.17 ms per token,    17.19 tokens per second)\n","llama_print_timings:       total time =     512.95 ms /    13 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23668.64 tokens per second)\n","llama_print_timings: prompt eval time =     473.79 ms /    15 tokens (   31.59 ms per token,    31.66 tokens per second)\n","llama_print_timings:        eval time =     182.54 ms /     3 runs   (   60.85 ms per token,    16.43 tokens per second)\n","llama_print_timings:       total time =     667.27 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       2.17 ms /    51 runs   (    0.04 ms per token, 23459.06 tokens per second)\n","llama_print_timings: prompt eval time =     452.04 ms /    16 tokens (   28.25 ms per token,    35.40 tokens per second)\n","llama_print_timings:        eval time =    3639.80 ms /    50 runs   (   72.80 ms per token,    13.74 tokens per second)\n","llama_print_timings:       total time =    4234.55 ms /    66 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.25 ms /     6 runs   (    0.04 ms per token, 24000.00 tokens per second)\n","llama_print_timings: prompt eval time =     446.39 ms /    14 tokens (   31.89 ms per token,    31.36 tokens per second)\n","llama_print_timings:        eval time =     330.56 ms /     5 runs   (   66.11 ms per token,    15.13 tokens per second)\n","llama_print_timings:       total time =     793.73 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.25 ms /     4 runs   (    0.06 ms per token, 15873.02 tokens per second)\n","llama_print_timings: prompt eval time =     445.90 ms /    15 tokens (   29.73 ms per token,    33.64 tokens per second)\n","llama_print_timings:        eval time =     195.12 ms /     3 runs   (   65.04 ms per token,    15.38 tokens per second)\n","llama_print_timings:       total time =     652.90 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.25 ms /     5 runs   (    0.05 ms per token, 20242.91 tokens per second)\n","llama_print_timings: prompt eval time =     431.26 ms /    14 tokens (   30.80 ms per token,    32.46 tokens per second)\n","llama_print_timings:        eval time =     245.32 ms /     4 runs   (   61.33 ms per token,    16.31 tokens per second)\n","llama_print_timings:       total time =     690.36 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23255.81 tokens per second)\n","llama_print_timings: prompt eval time =     449.49 ms /    15 tokens (   29.97 ms per token,    33.37 tokens per second)\n","llama_print_timings:        eval time =     193.38 ms /     3 runs   (   64.46 ms per token,    15.51 tokens per second)\n","llama_print_timings:       total time =     654.67 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.18 ms /     4 runs   (    0.05 ms per token, 21621.62 tokens per second)\n","llama_print_timings: prompt eval time =     439.56 ms /    15 tokens (   29.30 ms per token,    34.12 tokens per second)\n","llama_print_timings:        eval time =     199.08 ms /     3 runs   (   66.36 ms per token,    15.07 tokens per second)\n","llama_print_timings:       total time =     649.21 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.24 ms /     6 runs   (    0.04 ms per token, 24489.80 tokens per second)\n","llama_print_timings: prompt eval time =     436.14 ms /    14 tokens (   31.15 ms per token,    32.10 tokens per second)\n","llama_print_timings:        eval time =     336.67 ms /     5 runs   (   67.33 ms per token,    14.85 tokens per second)\n","llama_print_timings:       total time =     789.08 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 24242.42 tokens per second)\n","llama_print_timings: prompt eval time =     333.91 ms /    11 tokens (   30.36 ms per token,    32.94 tokens per second)\n","llama_print_timings:        eval time =     175.43 ms /     3 runs   (   58.48 ms per token,    17.10 tokens per second)\n","llama_print_timings:       total time =     520.63 ms /    14 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23668.64 tokens per second)\n","llama_print_timings: prompt eval time =     477.86 ms /    15 tokens (   31.86 ms per token,    31.39 tokens per second)\n","llama_print_timings:        eval time =     304.04 ms /     3 runs   (  101.35 ms per token,     9.87 tokens per second)\n","llama_print_timings:       total time =     793.39 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23255.81 tokens per second)\n","llama_print_timings: prompt eval time =     342.64 ms /    11 tokens (   31.15 ms per token,    32.10 tokens per second)\n","llama_print_timings:        eval time =     354.92 ms /     3 runs   (  118.31 ms per token,     8.45 tokens per second)\n","llama_print_timings:       total time =     708.94 ms /    14 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.16 ms /     4 runs   (    0.04 ms per token, 24844.72 tokens per second)\n","llama_print_timings: prompt eval time =     454.03 ms /    15 tokens (   30.27 ms per token,    33.04 tokens per second)\n","llama_print_timings:        eval time =     173.81 ms /     3 runs   (   57.94 ms per token,    17.26 tokens per second)\n","llama_print_timings:       total time =     638.76 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.18 ms /     4 runs   (    0.05 ms per token, 21978.02 tokens per second)\n","llama_print_timings: prompt eval time =     430.41 ms /    13 tokens (   33.11 ms per token,    30.20 tokens per second)\n","llama_print_timings:        eval time =     197.37 ms /     3 runs   (   65.79 ms per token,    15.20 tokens per second)\n","llama_print_timings:       total time =     639.03 ms /    16 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 23809.52 tokens per second)\n","llama_print_timings: prompt eval time =     433.09 ms /    15 tokens (   28.87 ms per token,    34.63 tokens per second)\n","llama_print_timings:        eval time =     253.03 ms /     4 runs   (   63.26 ms per token,    15.81 tokens per second)\n","llama_print_timings:       total time =     699.53 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 24271.84 tokens per second)\n","llama_print_timings: prompt eval time =     428.86 ms /    13 tokens (   32.99 ms per token,    30.31 tokens per second)\n","llama_print_timings:        eval time =     267.92 ms /     4 runs   (   66.98 ms per token,    14.93 tokens per second)\n","llama_print_timings:       total time =     709.93 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 24242.42 tokens per second)\n","llama_print_timings: prompt eval time =     432.76 ms /    15 tokens (   28.85 ms per token,    34.66 tokens per second)\n","llama_print_timings:        eval time =     177.77 ms /     3 runs   (   59.26 ms per token,    16.88 tokens per second)\n","llama_print_timings:       total time =     621.91 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.18 ms /     4 runs   (    0.04 ms per token, 22346.37 tokens per second)\n","llama_print_timings: prompt eval time =     429.11 ms /    13 tokens (   33.01 ms per token,    30.30 tokens per second)\n","llama_print_timings:        eval time =     172.80 ms /     3 runs   (   57.60 ms per token,    17.36 tokens per second)\n","llama_print_timings:       total time =     612.96 ms /    16 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23809.52 tokens per second)\n","llama_print_timings: prompt eval time =     438.76 ms /    15 tokens (   29.25 ms per token,    34.19 tokens per second)\n","llama_print_timings:        eval time =     173.37 ms /     3 runs   (   57.79 ms per token,    17.30 tokens per second)\n","llama_print_timings:       total time =     622.33 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.16 ms /     4 runs   (    0.04 ms per token, 24691.36 tokens per second)\n","llama_print_timings: prompt eval time =     438.19 ms /    14 tokens (   31.30 ms per token,    31.95 tokens per second)\n","llama_print_timings:        eval time =     171.16 ms /     3 runs   (   57.05 ms per token,    17.53 tokens per second)\n","llama_print_timings:       total time =     620.24 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.26 ms /     6 runs   (    0.04 ms per token, 22900.76 tokens per second)\n","llama_print_timings: prompt eval time =     437.29 ms /    14 tokens (   31.23 ms per token,    32.02 tokens per second)\n","llama_print_timings:        eval time =     334.01 ms /     5 runs   (   66.80 ms per token,    14.97 tokens per second)\n","llama_print_timings:       total time =     787.84 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23529.41 tokens per second)\n","llama_print_timings: prompt eval time =     323.04 ms /    10 tokens (   32.30 ms per token,    30.96 tokens per second)\n","llama_print_timings:        eval time =     180.49 ms /     3 runs   (   60.16 ms per token,    16.62 tokens per second)\n","llama_print_timings:       total time =     513.88 ms /    13 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.16 ms /     4 runs   (    0.04 ms per token, 24539.88 tokens per second)\n","llama_print_timings: prompt eval time =     448.97 ms /    13 tokens (   34.54 ms per token,    28.95 tokens per second)\n","llama_print_timings:        eval time =     184.72 ms /     3 runs   (   61.57 ms per token,    16.24 tokens per second)\n","llama_print_timings:       total time =     644.30 ms /    16 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 24096.39 tokens per second)\n","llama_print_timings: prompt eval time =     439.91 ms /    15 tokens (   29.33 ms per token,    34.10 tokens per second)\n","llama_print_timings:        eval time =     166.75 ms /     3 runs   (   55.58 ms per token,    17.99 tokens per second)\n","llama_print_timings:       total time =     617.49 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.24 ms /     6 runs   (    0.04 ms per token, 24691.36 tokens per second)\n","llama_print_timings: prompt eval time =     436.12 ms /    14 tokens (   31.15 ms per token,    32.10 tokens per second)\n","llama_print_timings:        eval time =     322.20 ms /     5 runs   (   64.44 ms per token,    15.52 tokens per second)\n","llama_print_timings:       total time =     774.94 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.16 ms /     4 runs   (    0.04 ms per token, 24539.88 tokens per second)\n","llama_print_timings: prompt eval time =     328.78 ms /    12 tokens (   27.40 ms per token,    36.50 tokens per second)\n","llama_print_timings:        eval time =     169.12 ms /     3 runs   (   56.37 ms per token,    17.74 tokens per second)\n","llama_print_timings:       total time =     509.10 ms /    15 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.18 ms /     4 runs   (    0.05 ms per token, 21621.62 tokens per second)\n","llama_print_timings: prompt eval time =     432.27 ms /    15 tokens (   28.82 ms per token,    34.70 tokens per second)\n","llama_print_timings:        eval time =     181.35 ms /     3 runs   (   60.45 ms per token,    16.54 tokens per second)\n","llama_print_timings:       total time =     624.91 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 23255.81 tokens per second)\n","llama_print_timings: prompt eval time =     434.84 ms /    14 tokens (   31.06 ms per token,    32.20 tokens per second)\n","llama_print_timings:        eval time =     234.92 ms /     4 runs   (   58.73 ms per token,    17.03 tokens per second)\n","llama_print_timings:       total time =     682.88 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 24154.59 tokens per second)\n","llama_print_timings: prompt eval time =     472.34 ms /    14 tokens (   33.74 ms per token,    29.64 tokens per second)\n","llama_print_timings:        eval time =     456.50 ms /     4 runs   (  114.13 ms per token,     8.76 tokens per second)\n","llama_print_timings:       total time =     943.05 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 22988.51 tokens per second)\n","llama_print_timings: prompt eval time =     445.39 ms /    15 tokens (   29.69 ms per token,    33.68 tokens per second)\n","llama_print_timings:        eval time =     370.72 ms /     3 runs   (  123.57 ms per token,     8.09 tokens per second)\n","llama_print_timings:       total time =     827.02 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.19 ms /     4 runs   (    0.05 ms per token, 21276.60 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =     298.80 ms /     4 runs   (   74.70 ms per token,    13.39 tokens per second)\n","llama_print_timings:       total time =     310.10 ms /     5 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.18 ms /     4 runs   (    0.04 ms per token, 22727.27 tokens per second)\n","llama_print_timings: prompt eval time =     329.43 ms /     9 tokens (   36.60 ms per token,    27.32 tokens per second)\n","llama_print_timings:        eval time =     169.46 ms /     3 runs   (   56.49 ms per token,    17.70 tokens per second)\n","llama_print_timings:       total time =     510.41 ms /    12 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23529.41 tokens per second)\n","llama_print_timings: prompt eval time =     437.45 ms /    14 tokens (   31.25 ms per token,    32.00 tokens per second)\n","llama_print_timings:        eval time =     168.33 ms /     3 runs   (   56.11 ms per token,    17.82 tokens per second)\n","llama_print_timings:       total time =     616.86 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.16 ms /     4 runs   (    0.04 ms per token, 24390.24 tokens per second)\n","llama_print_timings: prompt eval time =     332.73 ms /    12 tokens (   27.73 ms per token,    36.06 tokens per second)\n","llama_print_timings:        eval time =     174.30 ms /     3 runs   (   58.10 ms per token,    17.21 tokens per second)\n","llama_print_timings:       total time =     518.05 ms /    15 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       2.29 ms /    51 runs   (    0.04 ms per token, 22309.71 tokens per second)\n","llama_print_timings: prompt eval time =     447.38 ms /    16 tokens (   27.96 ms per token,    35.76 tokens per second)\n","llama_print_timings:        eval time =    3376.96 ms /    50 runs   (   67.54 ms per token,    14.81 tokens per second)\n","llama_print_timings:       total time =    3963.70 ms /    66 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.28 ms /     6 runs   (    0.05 ms per token, 21352.31 tokens per second)\n","llama_print_timings: prompt eval time =     425.02 ms /    14 tokens (   30.36 ms per token,    32.94 tokens per second)\n","llama_print_timings:        eval time =     305.68 ms /     5 runs   (   61.14 ms per token,    16.36 tokens per second)\n","llama_print_timings:       total time =     747.12 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 24390.24 tokens per second)\n","llama_print_timings: prompt eval time =     434.89 ms /    15 tokens (   28.99 ms per token,    34.49 tokens per second)\n","llama_print_timings:        eval time =     248.03 ms /     4 runs   (   62.01 ms per token,    16.13 tokens per second)\n","llama_print_timings:       total time =     696.78 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.18 ms /     4 runs   (    0.04 ms per token, 22857.14 tokens per second)\n","llama_print_timings: prompt eval time =     325.43 ms /    12 tokens (   27.12 ms per token,    36.87 tokens per second)\n","llama_print_timings:        eval time =     166.10 ms /     3 runs   (   55.37 ms per token,    18.06 tokens per second)\n","llama_print_timings:       total time =     502.56 ms /    15 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.25 ms /     6 runs   (    0.04 ms per token, 24291.50 tokens per second)\n","llama_print_timings: prompt eval time =     433.11 ms /    14 tokens (   30.94 ms per token,    32.32 tokens per second)\n","llama_print_timings:        eval time =     319.68 ms /     5 runs   (   63.94 ms per token,    15.64 tokens per second)\n","llama_print_timings:       total time =     769.48 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 24242.42 tokens per second)\n","llama_print_timings: prompt eval time =     428.72 ms /    15 tokens (   28.58 ms per token,    34.99 tokens per second)\n","llama_print_timings:        eval time =     184.01 ms /     3 runs   (   61.34 ms per token,    16.30 tokens per second)\n","llama_print_timings:       total time =     623.12 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 23364.49 tokens per second)\n","llama_print_timings: prompt eval time =     421.95 ms /    13 tokens (   32.46 ms per token,    30.81 tokens per second)\n","llama_print_timings:        eval time =     249.02 ms /     4 runs   (   62.26 ms per token,    16.06 tokens per second)\n","llama_print_timings:       total time =     684.52 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 24154.59 tokens per second)\n","llama_print_timings: prompt eval time =     428.70 ms /    14 tokens (   30.62 ms per token,    32.66 tokens per second)\n","llama_print_timings:        eval time =     248.75 ms /     4 runs   (   62.19 ms per token,    16.08 tokens per second)\n","llama_print_timings:       total time =     691.84 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.18 ms /     4 runs   (    0.05 ms per token, 21621.62 tokens per second)\n","llama_print_timings: prompt eval time =     338.97 ms /    11 tokens (   30.82 ms per token,    32.45 tokens per second)\n","llama_print_timings:        eval time =     349.21 ms /     3 runs   (  116.40 ms per token,     8.59 tokens per second)\n","llama_print_timings:       total time =     699.50 ms /    14 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.27 ms /     6 runs   (    0.05 ms per token, 22140.22 tokens per second)\n","llama_print_timings: prompt eval time =     441.49 ms /    14 tokens (   31.53 ms per token,    31.71 tokens per second)\n","llama_print_timings:        eval time =     496.37 ms /     5 runs   (   99.27 ms per token,    10.07 tokens per second)\n","llama_print_timings:       total time =     955.17 ms /    19 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.24 ms /     5 runs   (    0.05 ms per token, 20833.33 tokens per second)\n","llama_print_timings: prompt eval time =     448.73 ms /    14 tokens (   32.05 ms per token,    31.20 tokens per second)\n","llama_print_timings:        eval time =     231.24 ms /     4 runs   (   57.81 ms per token,    17.30 tokens per second)\n","llama_print_timings:       total time =     694.42 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.22 ms /     5 runs   (    0.04 ms per token, 22935.78 tokens per second)\n","llama_print_timings: prompt eval time =     424.50 ms /    13 tokens (   32.65 ms per token,    30.62 tokens per second)\n","llama_print_timings:        eval time =     270.97 ms /     4 runs   (   67.74 ms per token,    14.76 tokens per second)\n","llama_print_timings:       total time =     708.49 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.24 ms /     5 runs   (    0.05 ms per token, 20920.50 tokens per second)\n","llama_print_timings: prompt eval time =     422.10 ms /    14 tokens (   30.15 ms per token,    33.17 tokens per second)\n","llama_print_timings:        eval time =     243.35 ms /     4 runs   (   60.84 ms per token,    16.44 tokens per second)\n","llama_print_timings:       total time =     679.06 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.23 ms /     5 runs   (    0.05 ms per token, 21459.23 tokens per second)\n","llama_print_timings: prompt eval time =     424.30 ms /    13 tokens (   32.64 ms per token,    30.64 tokens per second)\n","llama_print_timings:        eval time =     241.58 ms /     4 runs   (   60.39 ms per token,    16.56 tokens per second)\n","llama_print_timings:       total time =     678.91 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.16 ms /     4 runs   (    0.04 ms per token, 24539.88 tokens per second)\n","llama_print_timings: prompt eval time =     427.00 ms /    15 tokens (   28.47 ms per token,    35.13 tokens per second)\n","llama_print_timings:        eval time =     173.69 ms /     3 runs   (   57.90 ms per token,    17.27 tokens per second)\n","llama_print_timings:       total time =     611.25 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 20408.16 tokens per second)\n","llama_print_timings: prompt eval time =     432.98 ms /    14 tokens (   30.93 ms per token,    32.33 tokens per second)\n","llama_print_timings:        eval time =     172.28 ms /     3 runs   (   57.43 ms per token,    17.41 tokens per second)\n","llama_print_timings:       total time =     618.00 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.21 ms /     5 runs   (    0.04 ms per token, 23809.52 tokens per second)\n","llama_print_timings: prompt eval time =     444.22 ms /    14 tokens (   31.73 ms per token,    31.52 tokens per second)\n","llama_print_timings:        eval time =     232.31 ms /     4 runs   (   58.08 ms per token,    17.22 tokens per second)\n","llama_print_timings:       total time =     689.59 ms /    18 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.20 ms /     5 runs   (    0.04 ms per token, 24752.48 tokens per second)\n","llama_print_timings: prompt eval time =     429.97 ms /    13 tokens (   33.07 ms per token,    30.23 tokens per second)\n","llama_print_timings:        eval time =     252.40 ms /     4 runs   (   63.10 ms per token,    15.85 tokens per second)\n","llama_print_timings:       total time =     696.26 ms /    17 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.16 ms /     4 runs   (    0.04 ms per token, 24691.36 tokens per second)\n","llama_print_timings: prompt eval time =     323.11 ms /    10 tokens (   32.31 ms per token,    30.95 tokens per second)\n","llama_print_timings:        eval time =     167.48 ms /     3 runs   (   55.83 ms per token,    17.91 tokens per second)\n","llama_print_timings:       total time =     500.98 ms /    13 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.19 ms /     4 runs   (    0.05 ms per token, 21052.63 tokens per second)\n","llama_print_timings: prompt eval time =     554.06 ms /    18 tokens (   30.78 ms per token,    32.49 tokens per second)\n","llama_print_timings:        eval time =     174.37 ms /     3 runs   (   58.12 ms per token,    17.20 tokens per second)\n","llama_print_timings:       total time =     739.83 ms /    21 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.17 ms /     4 runs   (    0.04 ms per token, 23529.41 tokens per second)\n","llama_print_timings: prompt eval time =     330.41 ms /    12 tokens (   27.53 ms per token,    36.32 tokens per second)\n","llama_print_timings:        eval time =     175.55 ms /     3 runs   (   58.52 ms per token,    17.09 tokens per second)\n","llama_print_timings:       total time =     516.11 ms /    15 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       0.20 ms /     4 runs   (    0.05 ms per token, 20100.50 tokens per second)\n","llama_print_timings: prompt eval time =     544.32 ms /    18 tokens (   30.24 ms per token,    33.07 tokens per second)\n","llama_print_timings:        eval time =     172.20 ms /     3 runs   (   57.40 ms per token,    17.42 tokens per second)\n","llama_print_timings:       total time =     728.61 ms /    21 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     550.16 ms\n","llama_print_timings:      sample time =       2.22 ms /    51 runs   (    0.04 ms per token, 23004.06 tokens per second)\n","llama_print_timings: prompt eval time =     436.39 ms /    16 tokens (   27.27 ms per token,    36.66 tokens per second)\n","llama_print_timings:        eval time =    3901.87 ms /    50 runs   (   78.04 ms per token,    12.81 tokens per second)\n","llama_print_timings:       total time =    4481.19 ms /    66 tokens\n"]}],"source":["# Import tqdm for progress tracking in notebooks\n","from tqdm.notebook import tqdm\n","\n","# Enable progress bar\n","tqdm.pandas()\n","\n","# Apply the LLaMA model to each review and generate a sentiment prediction\n","data_1['model_response'] = data_1['CleanedReview'].progress_apply(\n","    lambda x: generate_llama_response(instruction, x)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79,"status":"ok","timestamp":1751466020226,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"lEugBqp3zywG","outputId":"32612854-1ceb-4e85-d420-91e6781714a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Plain narrative, suitable for casual reading.\n"]}],"source":["# Checking what the input review looked like before being sent to LLaMA\n","i = 10\n","print(data_1.loc[i, 'CleanedReview'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1751466022050,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"S1KQGEMYeyKf","outputId":"eeb3adbd-052b-4020-ccdd-cc74cf18a5df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sure, I'd be happy to help! Here's the book review you provided:\n","\n","\"A thrilling and thought-provoking page-turner that will keep you up all night.\"\n","\n","My response: Positive\n"]}],"source":["# Checking what the input review looked like before being sent to LLaMA\n","i = 10\n","print(data_1.loc[i, 'model_response'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u5OgwTTbCqSZ"},"outputs":[],"source":["# Extract standardized sentiment label from text output\n","def extract_sentiment(text):\n","    text = str(text).lower()\n","    if \"positive\" in text:\n","        return \"Positive\"\n","    elif \"negative\" in text:\n","        return \"Negative\"\n","    elif \"neutral\" in text:\n","        return \"Neutral\"\n","    else:\n","        return \"Unknown\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":429},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1751461957235,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"ig3PHN943OJn","outputId":"027729f8-6224-4f6a-ae77-483422ce827d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentiment_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Neutral</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Neutral</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Neutral</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Neutral</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"],"text/plain":["0     Negative\n","1     Positive\n","2     Positive\n","3     Positive\n","4      Neutral\n","5     Positive\n","6     Negative\n","7      Neutral\n","8      Neutral\n","9      Neutral\n","10    Positive\n","Name: Sentiment_label, dtype: object"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["# Applying the function to the model response\n","data_1['Sentiment_label'] = data_1['model_response'].apply(extract_sentiment)\n","data_1['Sentiment_label'].head(11)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1751461962085,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"qo8YrnSD3ny5","outputId":"7e9b774d-0bea-4afa-ec11-185eec8539d0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>Sentiment_label</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Positive</th>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>Neutral</th>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>Negative</th>\n","      <td>26</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"],"text/plain":["Sentiment_label\n","Positive    41\n","Neutral     33\n","Negative    26\n","Name: count, dtype: int64"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["# A quick overview of how many reviews were labeled as Positive, Neutral, Negative, or Unknown\n","data_1['Sentiment_label'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1751461965494,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"Q4R8L6Tm_9R_","outputId":"13d126de-771d-4c26-9f52-09b61082ff26"},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["# Debugging why the sentiment couldn't be extracted correctly\n","data_1[data_1['Sentiment_label'] == 'Unknown']['model_response'].head().tolist()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1751461967670,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"0a6BLypJ8z4p","outputId":"b7ad083a-da5f-4743-ae0c-799b032ae30c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"final_data_1\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"ReviewText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Review #84: Uninspiring and boring.\",\n          \"Review #54: The best book I've read this year.\",\n          \"Review #71: Neither good nor bad, just fine.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CleanedReview\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"A waste of time.\",\n          \"Uninspiring and boring.\",\n          \"Poor character development.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Negative\",\n          \"Positive\",\n          \"Neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"final_data_1"},"text/html":["\n","  <div id=\"df-cc9bad2e-f159-4af2-9fba-1866b1056c38\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ReviewText</th>\n","      <th>Sentiment</th>\n","      <th>CleanedReview</th>\n","      <th>Sentiment_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Review #1: Highly disappointing read.</td>\n","      <td>0</td>\n","      <td>Highly disappointing read.</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Review #2: A page-turner with a powerful message.</td>\n","      <td>2</td>\n","      <td>A page-turner with a powerful message.</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Review #3: A masterpiece of storytelling.</td>\n","      <td>2</td>\n","      <td>A masterpiece of storytelling.</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Review #4: Heartwarming and inspiring read.</td>\n","      <td>2</td>\n","      <td>Heartwarming and inspiring read.</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Review #5: Neither good nor bad, just fine.</td>\n","      <td>1</td>\n","      <td>Neither good nor bad, just fine.</td>\n","      <td>Neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc9bad2e-f159-4af2-9fba-1866b1056c38')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cc9bad2e-f159-4af2-9fba-1866b1056c38 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cc9bad2e-f159-4af2-9fba-1866b1056c38');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-61f5cc34-8050-4793-80a5-553e770ac6b7\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-61f5cc34-8050-4793-80a5-553e770ac6b7')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-61f5cc34-8050-4793-80a5-553e770ac6b7 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                                          ReviewText  Sentiment  \\\n","0              Review #1: Highly disappointing read.          0   \n","1  Review #2: A page-turner with a powerful message.          2   \n","2          Review #3: A masterpiece of storytelling.          2   \n","3        Review #4: Heartwarming and inspiring read.          2   \n","4        Review #5: Neither good nor bad, just fine.          1   \n","\n","                            CleanedReview Sentiment_label  \n","0              Highly disappointing read.        Negative  \n","1  A page-turner with a powerful message.        Positive  \n","2          A masterpiece of storytelling.        Positive  \n","3        Heartwarming and inspiring read.        Positive  \n","4        Neither good nor bad, just fine.         Neutral  "]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["# Store the cleaned version of the dataset in final_data_1\n","final_data_1 = data_1.drop(['model_response'], axis=1)\n","final_data_1.head()"]},{"cell_type":"markdown","metadata":{"id":"7ys6M2RDz8MB"},"source":["#### LLaMA vs. True Sentiment Labels: Evaluation of Prediction Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1751462056134,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"bJAfiYkFxeQD","outputId":"07390795-fbfc-4572-beee-6e8b94014702"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 1.0\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","    Negative       1.00      1.00      1.00        24\n","     Neutral       1.00      1.00      1.00        32\n","    Positive       1.00      1.00      1.00        33\n","\n","    accuracy                           1.00        89\n","   macro avg       1.00      1.00      1.00        89\n","weighted avg       1.00      1.00      1.00        89\n","\n"]}],"source":["\n","# Normalize predictions\n","data_1['model_response'] = data_1['model_response'].str.strip().str.capitalize()\n","\n","# Map LLaMA predictions to numeric values\n","sentiment_map = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n","data_1['Sentiment_label'] = data_1['model_response'].map(sentiment_map)\n","\n","# Drop invalid predictions\n","data_eval = data_1.dropna(subset=['Sentiment_label'])\n","\n","y_true = data_eval['Sentiment_label']\n","y_pred = data_eval['Sentiment_label']\n","\n","accuracy = accuracy_score(y_true, y_pred)\n","report = classification_report(y_true, y_pred, target_names=['Negative', 'Neutral', 'Positive'])\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"\\nClassification Report:\\n\", report)"]},{"cell_type":"markdown","metadata":{"id":"EMPA09t94bvg"},"source":["**Summary:**\n","- Accuracy: 1.0: Indicates the model predicted every label correctly"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":155,"status":"ok","timestamp":1751462067825,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"D4AWAU8S9nai","outputId":"db4ffd25-557b-447f-c8cb-e127b3440df8"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","# Map numeric sentiment to label\n","sentiment_labels = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n","labelled_counts = data_1['Sentiment_label'].map(sentiment_labels).value_counts()\n","total = labelled_counts.sum()\n","\n","# Plot\n","labelled_counts.plot(kind='bar', color='skyblue')\n","plt.title(\"Model–Predicted Sentiment Distribution\")\n","plt.ylabel(\"Number of Reviews\")\n","plt.xticks(rotation=0)\n","plt.grid(axis='y')\n","\n","# Add count and percentage on top of bars\n","for i, (label, count) in enumerate(labelled_counts.items()):\n","    percent = (count / total) * 100\n","    plt.text(i, count - 2, f'{count} ({percent:.1f}%)', ha='center', fontsize=10)\n","\n","plt.show()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"FQXmRAtuYUrH"},"source":["**Overall Sentiment Classification Using LLaMA:**\n","\n","In the first stage of the project, I used a Large Language Model (LLaMA) to classify the overall sentiment of book reviews as Positive, Neutral, or Negative. Each review was passed through the model using a structured prompt designed to restrict the output to a single sentiment label.\n","\n","The raw predictions were then cleaned and standardized using a custom parsing function to ensure consistency across all outputs."]},{"cell_type":"markdown","metadata":{"id":"RX5JjiOe5ZFW"},"source":["### 2. Understanding Reader Sentiment with LLaMA: Overall Sentiment, Aspect-Level Insights, and Liked/Disliked Features"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1751484271609,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"fXCbMOHqiLRe"},"outputs":[],"source":["def generate_llama_response_2(instruction, review):\n","    if not isinstance(review, str) or len(review.strip()) < 5:\n","        return \"Unknown\"\n","\n","    # Build the prompt with clear structure\n","    prompt = f\"\"\"[INST]<<SYS>>\n","{instruction.strip()}\n","<</SYS>>\n","\n","Here is the book review: {review.strip()}\n","[/INST]\"\"\"\n","\n","    response = llm(\n","        prompt=prompt,\n","        max_tokens=512,\n","        temperature=0.01,\n","        top_p=1.0,\n","        top_k=0,\n","        repeat_penalty=1.0,\n","        echo=False,\n","        seed=42,\n","    )\n","\n","    result = response[\"choices\"][0][\"text\"].strip()\n","\n","    if not result or \"please provide\" in result.lower():\n","        return \"Failed to interpret input\"\n","\n","    return result"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1751485466137,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"74VaoNfr5Yqi"},"outputs":[],"source":["# Create a copy of the first 200 rows from the original dataset for faster processing\n","data_4 = data.iloc[:100].copy()"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1751485467140,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"5wxt130zsT-N"},"outputs":[],"source":["# Clean the review without adding misleading cues or confusing the LLaMA format\n","data_4[\"CleanedReview\"] = data_4[\"ReviewText\"].str.replace(r\"^Review\\s+#\\d+:\\s*\", \"\", regex=True)"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1751485468286,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"TBhlayz5Kpjv"},"outputs":[],"source":["# defining the instructions for the model\n","\n","instruction_2 = \"\"\"\n","You are an AI analyzing book reviews.\n","\n","Your task is to:\n","1. Classify the **overall sentiment** of the review as one of the following **exact** words:\n","   - \"Positive\"\n","   - \"Negative\"\n","   - \"Neutral\"\n","\n","2. Determine the sentiment of the following aspects of the book using one of:\n","   - \"Positive\"\n","   - \"Negative\"\n","   - \"Neutral\"\n","   - \"Not Applicable\" (if not mentioned)\n","\n","   Aspects:\n","   - Writing Style\n","   - Emotional Impact\n","\n","3. Identify liked or disliked features for the following:\n","   - Pacing\n","   - Ending\n","\n","Return a list of quoted features for each. If no features are found, return an empty list.\n","\n","4. Write a polite, empathetic response to the customer. Begin with a thank you. Then:\n","   - If **Positive**, say you’re glad they enjoyed the book and would love to have them read again.\n","   - If **Neutral**, thank them and ask what could have improved their experience.\n","   - If **Negative**, apologize and say their feedback will be reviewed.\n","\n","Output only the **exact JSON object below** — nothing else. All values must be strings. Lists must contain strings in double quotes.\n","\n","{\n","    \"Overall Sentiment\": \"your_sentiment_prediction\",\n","    \"Writing Style\": \"your_sentiment_prediction\",\n","    \"Emotional Impact\": \"your_sentiment_prediction\",\n","    \"Pacing\": [\"liked or disliked features\"],\n","    \"Ending\": [\"liked or disliked features\"],\n","    \"Response\": \"your_response_to_the_customer_review\"\n","}\n","\"\"\""]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["780654f355a14e42b0b17ff8f4f4459c","5c6cc39262c74be3958843faa5a839a0","c4e2b8c1387542ea9fd4286976bfe3a2","cdf813d832604f8c8d70f7e2d5bacac9","a17f8662096341d5b87415a9fbef2ece","abd152c0c1ca414abbb64e05373f89c4","d5d2eefd768d4c1cbd6650ee3ab3bcdc","09085677b5b845daa73d5f3da1767b2f","49663507456349668e1c597cdc4c5c58","f9f8e2b2073642b99ecedfe281b18559","31a301da77be4c14b2a5282692a9db23"]},"executionInfo":{"elapsed":1891687,"status":"ok","timestamp":1751488171370,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"ifQjhn6v5569","outputId":"c9fa37f5-b4b7-4b35-d93f-7a59e4bc5778"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"780654f355a14e42b0b17ff8f4f4459c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"stream","name":"stderr","text":["Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     553.52 ms /   330 runs   (    1.68 ms per token,   596.18 tokens per second)\n","llama_print_timings: prompt eval time =     387.98 ms /    11 tokens (   35.27 ms per token,    28.35 tokens per second)\n","llama_print_timings:        eval time =   27216.41 ms /   329 runs   (   82.72 ms per token,    12.09 tokens per second)\n","llama_print_timings:       total time =   29246.49 ms /   340 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     693.98 ms /   402 runs   (    1.73 ms per token,   579.27 tokens per second)\n","llama_print_timings: prompt eval time =     451.77 ms /    15 tokens (   30.12 ms per token,    33.20 tokens per second)\n","llama_print_timings:        eval time =   30026.99 ms /   401 runs   (   74.88 ms per token,    13.35 tokens per second)\n","llama_print_timings:       total time =   32726.65 ms /   416 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     551.48 ms /   329 runs   (    1.68 ms per token,   596.57 tokens per second)\n","llama_print_timings: prompt eval time =     430.29 ms /    13 tokens (   33.10 ms per token,    30.21 tokens per second)\n","llama_print_timings:        eval time =   25025.45 ms /   328 runs   (   76.30 ms per token,    13.11 tokens per second)\n","llama_print_timings:       total time =   27074.42 ms /   341 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     236.76 ms /   139 runs   (    1.70 ms per token,   587.08 tokens per second)\n","llama_print_timings: prompt eval time =     476.73 ms /    14 tokens (   34.05 ms per token,    29.37 tokens per second)\n","llama_print_timings:        eval time =   10746.91 ms /   138 runs   (   77.88 ms per token,    12.84 tokens per second)\n","llama_print_timings:       total time =   11920.33 ms /   152 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     514.22 ms /   305 runs   (    1.69 ms per token,   593.13 tokens per second)\n","llama_print_timings: prompt eval time =     467.33 ms /    14 tokens (   33.38 ms per token,    29.96 tokens per second)\n","llama_print_timings:        eval time =   24440.85 ms /   304 runs   (   80.40 ms per token,    12.44 tokens per second)\n","llama_print_timings:       total time =   26474.50 ms /   318 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     628.89 ms /   373 runs   (    1.69 ms per token,   593.11 tokens per second)\n","llama_print_timings: prompt eval time =     363.66 ms /    12 tokens (   30.30 ms per token,    33.00 tokens per second)\n","llama_print_timings:        eval time =   29480.15 ms /   372 runs   (   79.25 ms per token,    12.62 tokens per second)\n","llama_print_timings:       total time =   31782.38 ms /   384 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     610.91 ms /   361 runs   (    1.69 ms per token,   590.92 tokens per second)\n","llama_print_timings: prompt eval time =     458.99 ms /    15 tokens (   30.60 ms per token,    32.68 tokens per second)\n","llama_print_timings:        eval time =   28128.82 ms /   360 runs   (   78.14 ms per token,    12.80 tokens per second)\n","llama_print_timings:       total time =   30478.72 ms /   375 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     597.99 ms /   351 runs   (    1.70 ms per token,   586.97 tokens per second)\n","llama_print_timings: prompt eval time =     459.48 ms /    13 tokens (   35.34 ms per token,    28.29 tokens per second)\n","llama_print_timings:        eval time =   27009.81 ms /   350 runs   (   77.17 ms per token,    12.96 tokens per second)\n","llama_print_timings:       total time =   29327.40 ms /   363 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     598.68 ms /   358 runs   (    1.67 ms per token,   597.98 tokens per second)\n","llama_print_timings: prompt eval time =     465.02 ms /    13 tokens (   35.77 ms per token,    27.96 tokens per second)\n","llama_print_timings:        eval time =   27461.45 ms /   357 runs   (   76.92 ms per token,    13.00 tokens per second)\n","llama_print_timings:       total time =   29788.85 ms /   370 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     560.27 ms /   332 runs   (    1.69 ms per token,   592.57 tokens per second)\n","llama_print_timings: prompt eval time =     484.56 ms /    15 tokens (   32.30 ms per token,    30.96 tokens per second)\n","llama_print_timings:        eval time =   26422.47 ms /   331 runs   (   79.83 ms per token,    12.53 tokens per second)\n","llama_print_timings:       total time =   28646.85 ms /   346 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     532.84 ms /   314 runs   (    1.70 ms per token,   589.29 tokens per second)\n","llama_print_timings: prompt eval time =     478.91 ms /    16 tokens (   29.93 ms per token,    33.41 tokens per second)\n","llama_print_timings:        eval time =   24304.07 ms /   313 runs   (   77.65 ms per token,    12.88 tokens per second)\n","llama_print_timings:       total time =   26440.71 ms /   329 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     607.58 ms /   356 runs   (    1.71 ms per token,   585.93 tokens per second)\n","llama_print_timings: prompt eval time =     350.12 ms /    12 tokens (   29.18 ms per token,    34.27 tokens per second)\n","llama_print_timings:        eval time =   27469.25 ms /   355 runs   (   77.38 ms per token,    12.92 tokens per second)\n","llama_print_timings:       total time =   29720.13 ms /   367 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     607.90 ms /   358 runs   (    1.70 ms per token,   588.91 tokens per second)\n","llama_print_timings: prompt eval time =     448.55 ms /    13 tokens (   34.50 ms per token,    28.98 tokens per second)\n","llama_print_timings:        eval time =   28676.94 ms /   357 runs   (   80.33 ms per token,    12.45 tokens per second)\n","llama_print_timings:       total time =   31027.03 ms /   370 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     514.78 ms /   305 runs   (    1.69 ms per token,   592.48 tokens per second)\n","llama_print_timings: prompt eval time =     468.21 ms /    14 tokens (   33.44 ms per token,    29.90 tokens per second)\n","llama_print_timings:        eval time =   23725.47 ms /   304 runs   (   78.04 ms per token,    12.81 tokens per second)\n","llama_print_timings:       total time =   25794.76 ms /   318 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     206.94 ms /   123 runs   (    1.68 ms per token,   594.38 tokens per second)\n","llama_print_timings: prompt eval time =     451.78 ms /    15 tokens (   30.12 ms per token,    33.20 tokens per second)\n","llama_print_timings:        eval time =    9536.49 ms /   122 runs   (   78.17 ms per token,    12.79 tokens per second)\n","llama_print_timings:       total time =   10612.71 ms /   137 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     526.45 ms /   314 runs   (    1.68 ms per token,   596.45 tokens per second)\n","llama_print_timings: prompt eval time =     474.37 ms /    16 tokens (   29.65 ms per token,    33.73 tokens per second)\n","llama_print_timings:        eval time =   24307.71 ms /   313 runs   (   77.66 ms per token,    12.88 tokens per second)\n","llama_print_timings:       total time =   26440.37 ms /   329 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     587.66 ms /   349 runs   (    1.68 ms per token,   593.88 tokens per second)\n","llama_print_timings: prompt eval time =     445.79 ms /    13 tokens (   34.29 ms per token,    29.16 tokens per second)\n","llama_print_timings:        eval time =   26826.33 ms /   348 runs   (   77.09 ms per token,    12.97 tokens per second)\n","llama_print_timings:       total time =   29120.05 ms /   361 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     578.47 ms /   349 runs   (    1.66 ms per token,   603.32 tokens per second)\n","llama_print_timings: prompt eval time =     453.18 ms /    14 tokens (   32.37 ms per token,    30.89 tokens per second)\n","llama_print_timings:        eval time =   27447.70 ms /   348 runs   (   78.87 ms per token,    12.68 tokens per second)\n","llama_print_timings:       total time =   29725.34 ms /   362 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     702.95 ms /   416 runs   (    1.69 ms per token,   591.79 tokens per second)\n","llama_print_timings: prompt eval time =     450.50 ms /    13 tokens (   34.65 ms per token,    28.86 tokens per second)\n","llama_print_timings:        eval time =   32870.51 ms /   415 runs   (   79.21 ms per token,    12.63 tokens per second)\n","llama_print_timings:       total time =   35551.08 ms /   428 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     512.91 ms /   303 runs   (    1.69 ms per token,   590.74 tokens per second)\n","llama_print_timings: prompt eval time =     328.13 ms /    11 tokens (   29.83 ms per token,    33.52 tokens per second)\n","llama_print_timings:        eval time =   23581.80 ms /   302 runs   (   78.09 ms per token,    12.81 tokens per second)\n","llama_print_timings:       total time =   25513.49 ms /   313 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     626.66 ms /   373 runs   (    1.68 ms per token,   595.22 tokens per second)\n","llama_print_timings: prompt eval time =     346.27 ms /    12 tokens (   28.86 ms per token,    34.66 tokens per second)\n","llama_print_timings:        eval time =   28990.26 ms /   372 runs   (   77.93 ms per token,    12.83 tokens per second)\n","llama_print_timings:       total time =   31174.07 ms /   384 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     646.97 ms /   383 runs   (    1.69 ms per token,   591.99 tokens per second)\n","llama_print_timings: prompt eval time =     454.91 ms /    15 tokens (   30.33 ms per token,    32.97 tokens per second)\n","llama_print_timings:        eval time =   29930.69 ms /   382 runs   (   78.35 ms per token,    12.76 tokens per second)\n","llama_print_timings:       total time =   32434.12 ms /   397 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     227.95 ms /   134 runs   (    1.70 ms per token,   587.85 tokens per second)\n","llama_print_timings: prompt eval time =     461.00 ms /    14 tokens (   32.93 ms per token,    30.37 tokens per second)\n","llama_print_timings:        eval time =   10284.52 ms /   133 runs   (   77.33 ms per token,    12.93 tokens per second)\n","llama_print_timings:       total time =   11442.21 ms /   147 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     648.76 ms /   383 runs   (    1.69 ms per token,   590.36 tokens per second)\n","llama_print_timings: prompt eval time =     454.53 ms /    15 tokens (   30.30 ms per token,    33.00 tokens per second)\n","llama_print_timings:        eval time =   29751.83 ms /   382 runs   (   77.88 ms per token,    12.84 tokens per second)\n","llama_print_timings:       total time =   32267.59 ms /   397 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     235.61 ms /   138 runs   (    1.71 ms per token,   585.70 tokens per second)\n","llama_print_timings: prompt eval time =     461.39 ms /    13 tokens (   35.49 ms per token,    28.18 tokens per second)\n","llama_print_timings:        eval time =   10423.50 ms /   137 runs   (   76.08 ms per token,    13.14 tokens per second)\n","llama_print_timings:       total time =   11604.80 ms /   150 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     685.75 ms /   402 runs   (    1.71 ms per token,   586.22 tokens per second)\n","llama_print_timings: prompt eval time =     508.96 ms /    15 tokens (   33.93 ms per token,    29.47 tokens per second)\n","llama_print_timings:        eval time =   31285.90 ms /   401 runs   (   78.02 ms per token,    12.82 tokens per second)\n","llama_print_timings:       total time =   33980.40 ms /   416 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     614.34 ms /   361 runs   (    1.70 ms per token,   587.63 tokens per second)\n","llama_print_timings: prompt eval time =     476.69 ms /    15 tokens (   31.78 ms per token,    31.47 tokens per second)\n","llama_print_timings:        eval time =   28640.30 ms /   360 runs   (   79.56 ms per token,    12.57 tokens per second)\n","llama_print_timings:       total time =   31066.44 ms /   375 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     648.93 ms /   381 runs   (    1.70 ms per token,   587.12 tokens per second)\n","llama_print_timings: prompt eval time =     440.83 ms /    13 tokens (   33.91 ms per token,    29.49 tokens per second)\n","llama_print_timings:        eval time =   29152.64 ms /   380 runs   (   76.72 ms per token,    13.03 tokens per second)\n","llama_print_timings:       total time =   31650.86 ms /   393 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     645.23 ms /   381 runs   (    1.69 ms per token,   590.49 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =   30145.69 ms /   381 runs   (   79.12 ms per token,    12.64 tokens per second)\n","llama_print_timings:       total time =   32212.77 ms /   382 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     601.86 ms /   351 runs   (    1.71 ms per token,   583.19 tokens per second)\n","llama_print_timings: prompt eval time =     447.16 ms /    13 tokens (   34.40 ms per token,    29.07 tokens per second)\n","llama_print_timings:        eval time =   27254.78 ms /   350 runs   (   77.87 ms per token,    12.84 tokens per second)\n","llama_print_timings:       total time =   29602.54 ms /   363 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     222.85 ms /   130 runs   (    1.71 ms per token,   583.36 tokens per second)\n","llama_print_timings: prompt eval time =     467.07 ms /    16 tokens (   29.19 ms per token,    34.26 tokens per second)\n","llama_print_timings:        eval time =   10183.87 ms /   129 runs   (   78.94 ms per token,    12.67 tokens per second)\n","llama_print_timings:       total time =   11331.91 ms /   145 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     517.12 ms /   305 runs   (    1.70 ms per token,   589.80 tokens per second)\n","llama_print_timings: prompt eval time =     463.26 ms /    14 tokens (   33.09 ms per token,    30.22 tokens per second)\n","llama_print_timings:        eval time =   23827.81 ms /   304 runs   (   78.38 ms per token,    12.76 tokens per second)\n","llama_print_timings:       total time =   25916.53 ms /   318 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     607.38 ms /   358 runs   (    1.70 ms per token,   589.42 tokens per second)\n","llama_print_timings: prompt eval time =     442.79 ms /    13 tokens (   34.06 ms per token,    29.36 tokens per second)\n","llama_print_timings:        eval time =   28464.75 ms /   357 runs   (   79.73 ms per token,    12.54 tokens per second)\n","llama_print_timings:       total time =   30822.53 ms /   370 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     521.33 ms /   305 runs   (    1.71 ms per token,   585.04 tokens per second)\n","llama_print_timings: prompt eval time =     447.25 ms /    14 tokens (   31.95 ms per token,    31.30 tokens per second)\n","llama_print_timings:        eval time =   23544.38 ms /   304 runs   (   77.45 ms per token,    12.91 tokens per second)\n","llama_print_timings:       total time =   25632.24 ms /   318 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     605.86 ms /   356 runs   (    1.70 ms per token,   587.59 tokens per second)\n","llama_print_timings: prompt eval time =     339.55 ms /    12 tokens (   28.30 ms per token,    35.34 tokens per second)\n","llama_print_timings:        eval time =   27697.38 ms /   355 runs   (   78.02 ms per token,    12.82 tokens per second)\n","llama_print_timings:       total time =   29960.47 ms /   367 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     681.37 ms /   402 runs   (    1.69 ms per token,   589.99 tokens per second)\n","llama_print_timings: prompt eval time =     487.36 ms /    15 tokens (   32.49 ms per token,    30.78 tokens per second)\n","llama_print_timings:        eval time =   31457.56 ms /   401 runs   (   78.45 ms per token,    12.75 tokens per second)\n","llama_print_timings:       total time =   34118.78 ms /   416 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     647.02 ms /   381 runs   (    1.70 ms per token,   588.85 tokens per second)\n","llama_print_timings: prompt eval time =     447.24 ms /    13 tokens (   34.40 ms per token,    29.07 tokens per second)\n","llama_print_timings:        eval time =   30031.66 ms /   380 runs   (   79.03 ms per token,    12.65 tokens per second)\n","llama_print_timings:       total time =   32539.77 ms /   393 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     602.97 ms /   356 runs   (    1.69 ms per token,   590.41 tokens per second)\n","llama_print_timings: prompt eval time =     345.78 ms /    12 tokens (   28.81 ms per token,    34.70 tokens per second)\n","llama_print_timings:        eval time =   27654.39 ms /   355 runs   (   77.90 ms per token,    12.84 tokens per second)\n","llama_print_timings:       total time =   29916.21 ms /   367 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     650.71 ms /   383 runs   (    1.70 ms per token,   588.59 tokens per second)\n","llama_print_timings: prompt eval time =     452.09 ms /    15 tokens (   30.14 ms per token,    33.18 tokens per second)\n","llama_print_timings:        eval time =   30334.02 ms /   382 runs   (   79.41 ms per token,    12.59 tokens per second)\n","llama_print_timings:       total time =   32847.10 ms /   397 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     234.74 ms /   139 runs   (    1.69 ms per token,   592.15 tokens per second)\n","llama_print_timings: prompt eval time =     450.59 ms /    14 tokens (   32.19 ms per token,    31.07 tokens per second)\n","llama_print_timings:        eval time =   10877.88 ms /   138 runs   (   78.83 ms per token,    12.69 tokens per second)\n","llama_print_timings:       total time =   12040.87 ms /   152 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     235.63 ms /   139 runs   (    1.70 ms per token,   589.90 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =   10980.66 ms /   139 runs   (   79.00 ms per token,    12.66 tokens per second)\n","llama_print_timings:       total time =   11694.62 ms /   140 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     597.19 ms /   349 runs   (    1.71 ms per token,   584.40 tokens per second)\n","llama_print_timings: prompt eval time =     459.34 ms /    14 tokens (   32.81 ms per token,    30.48 tokens per second)\n","llama_print_timings:        eval time =   27171.52 ms /   348 runs   (   78.08 ms per token,    12.81 tokens per second)\n","llama_print_timings:       total time =   29530.50 ms /   362 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     219.74 ms /   128 runs   (    1.72 ms per token,   582.50 tokens per second)\n","llama_print_timings: prompt eval time =     443.94 ms /    14 tokens (   31.71 ms per token,    31.54 tokens per second)\n","llama_print_timings:        eval time =    9980.18 ms /   127 runs   (   78.58 ms per token,    12.73 tokens per second)\n","llama_print_timings:       total time =   11087.90 ms /   141 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     592.01 ms /   350 runs   (    1.69 ms per token,   591.21 tokens per second)\n","llama_print_timings: prompt eval time =     335.32 ms /    10 tokens (   33.53 ms per token,    29.82 tokens per second)\n","llama_print_timings:        eval time =   27773.87 ms /   349 runs   (   79.58 ms per token,    12.57 tokens per second)\n","llama_print_timings:       total time =   29978.06 ms /   359 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     238.21 ms /   139 runs   (    1.71 ms per token,   583.53 tokens per second)\n","llama_print_timings: prompt eval time =     474.36 ms /    14 tokens (   33.88 ms per token,    29.51 tokens per second)\n","llama_print_timings:        eval time =   10781.44 ms /   138 runs   (   78.13 ms per token,    12.80 tokens per second)\n","llama_print_timings:       total time =   11978.06 ms /   152 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     535.77 ms /   314 runs   (    1.71 ms per token,   586.08 tokens per second)\n","llama_print_timings: prompt eval time =     467.70 ms /    16 tokens (   29.23 ms per token,    34.21 tokens per second)\n","llama_print_timings:        eval time =   24388.34 ms /   313 runs   (   77.92 ms per token,    12.83 tokens per second)\n","llama_print_timings:       total time =   26533.43 ms /   329 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     597.77 ms /   349 runs   (    1.71 ms per token,   583.83 tokens per second)\n","llama_print_timings: prompt eval time =     450.42 ms /    14 tokens (   32.17 ms per token,    31.08 tokens per second)\n","llama_print_timings:        eval time =   27123.88 ms /   348 runs   (   77.94 ms per token,    12.83 tokens per second)\n","llama_print_timings:       total time =   29458.48 ms /   362 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     619.98 ms /   361 runs   (    1.72 ms per token,   582.28 tokens per second)\n","llama_print_timings: prompt eval time =     453.43 ms /    15 tokens (   30.23 ms per token,    33.08 tokens per second)\n","llama_print_timings:        eval time =   28295.63 ms /   360 runs   (   78.60 ms per token,    12.72 tokens per second)\n","llama_print_timings:       total time =   30696.10 ms /   375 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     611.66 ms /   358 runs   (    1.71 ms per token,   585.30 tokens per second)\n","llama_print_timings: prompt eval time =     450.11 ms /    13 tokens (   34.62 ms per token,    28.88 tokens per second)\n","llama_print_timings:        eval time =   27844.06 ms /   357 runs   (   77.99 ms per token,    12.82 tokens per second)\n","llama_print_timings:       total time =   30237.21 ms /   370 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     690.65 ms /   402 runs   (    1.72 ms per token,   582.06 tokens per second)\n","llama_print_timings: prompt eval time =     461.32 ms /    15 tokens (   30.75 ms per token,    32.52 tokens per second)\n","llama_print_timings:        eval time =   31443.50 ms /   401 runs   (   78.41 ms per token,    12.75 tokens per second)\n","llama_print_timings:       total time =   34109.38 ms /   416 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     624.56 ms /   361 runs   (    1.73 ms per token,   578.01 tokens per second)\n","llama_print_timings: prompt eval time =     461.88 ms /    15 tokens (   30.79 ms per token,    32.48 tokens per second)\n","llama_print_timings:        eval time =   27626.61 ms /   360 runs   (   76.74 ms per token,    13.03 tokens per second)\n","llama_print_timings:       total time =   30080.14 ms /   375 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     603.76 ms /   349 runs   (    1.73 ms per token,   578.04 tokens per second)\n","llama_print_timings: prompt eval time =     481.26 ms /    14 tokens (   34.38 ms per token,    29.09 tokens per second)\n","llama_print_timings:        eval time =   27618.73 ms /   348 runs   (   79.36 ms per token,    12.60 tokens per second)\n","llama_print_timings:       total time =   30021.32 ms /   362 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     572.25 ms /   330 runs   (    1.73 ms per token,   576.67 tokens per second)\n","llama_print_timings: prompt eval time =     345.15 ms /    11 tokens (   31.38 ms per token,    31.87 tokens per second)\n","llama_print_timings:        eval time =   25492.02 ms /   329 runs   (   77.48 ms per token,    12.91 tokens per second)\n","llama_print_timings:       total time =   27643.39 ms /   340 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     598.82 ms /   350 runs   (    1.71 ms per token,   584.48 tokens per second)\n","llama_print_timings: prompt eval time =     475.19 ms /    15 tokens (   31.68 ms per token,    31.57 tokens per second)\n","llama_print_timings:        eval time =   27413.08 ms /   349 runs   (   78.55 ms per token,    12.73 tokens per second)\n","llama_print_timings:       total time =   29789.17 ms /   364 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     519.07 ms /   303 runs   (    1.71 ms per token,   583.73 tokens per second)\n","llama_print_timings: prompt eval time =     353.62 ms /    11 tokens (   32.15 ms per token,    31.11 tokens per second)\n","llama_print_timings:        eval time =   23623.10 ms /   302 runs   (   78.22 ms per token,    12.78 tokens per second)\n","llama_print_timings:       total time =   25613.67 ms /   313 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     677.06 ms /   402 runs   (    1.68 ms per token,   593.75 tokens per second)\n","llama_print_timings: prompt eval time =     443.39 ms /    15 tokens (   29.56 ms per token,    33.83 tokens per second)\n","llama_print_timings:        eval time =   31133.47 ms /   401 runs   (   77.64 ms per token,    12.88 tokens per second)\n","llama_print_timings:       total time =   33623.13 ms /   416 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     558.94 ms /   329 runs   (    1.70 ms per token,   588.61 tokens per second)\n","llama_print_timings: prompt eval time =     456.06 ms /    13 tokens (   35.08 ms per token,    28.51 tokens per second)\n","llama_print_timings:        eval time =   26077.28 ms /   328 runs   (   79.50 ms per token,    12.58 tokens per second)\n","llama_print_timings:       total time =   28302.49 ms /   341 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     566.17 ms /   332 runs   (    1.71 ms per token,   586.40 tokens per second)\n","llama_print_timings: prompt eval time =     479.33 ms /    15 tokens (   31.96 ms per token,    31.29 tokens per second)\n","llama_print_timings:        eval time =   25531.01 ms /   331 runs   (   77.13 ms per token,    12.96 tokens per second)\n","llama_print_timings:       total time =   27790.73 ms /   346 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     594.74 ms /   349 runs   (    1.70 ms per token,   586.81 tokens per second)\n","llama_print_timings: prompt eval time =     442.29 ms /    13 tokens (   34.02 ms per token,    29.39 tokens per second)\n","llama_print_timings:        eval time =   26899.90 ms /   348 runs   (   77.30 ms per token,    12.94 tokens per second)\n","llama_print_timings:       total time =   29232.83 ms /   361 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     597.83 ms /   350 runs   (    1.71 ms per token,   585.45 tokens per second)\n","llama_print_timings: prompt eval time =     459.95 ms /    15 tokens (   30.66 ms per token,    32.61 tokens per second)\n","llama_print_timings:        eval time =   27523.89 ms /   349 runs   (   78.87 ms per token,    12.68 tokens per second)\n","llama_print_timings:       total time =   29888.12 ms /   364 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     235.99 ms /   138 runs   (    1.71 ms per token,   584.78 tokens per second)\n","llama_print_timings: prompt eval time =     456.35 ms /    13 tokens (   35.10 ms per token,    28.49 tokens per second)\n","llama_print_timings:        eval time =   10782.91 ms /   137 runs   (   78.71 ms per token,    12.71 tokens per second)\n","llama_print_timings:       total time =   11959.66 ms /   150 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     599.68 ms /   350 runs   (    1.71 ms per token,   583.65 tokens per second)\n","llama_print_timings: prompt eval time =     441.34 ms /    15 tokens (   29.42 ms per token,    33.99 tokens per second)\n","llama_print_timings:        eval time =   27254.93 ms /   349 runs   (   78.09 ms per token,    12.81 tokens per second)\n","llama_print_timings:       total time =   29604.30 ms /   364 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     673.73 ms /   393 runs   (    1.71 ms per token,   583.32 tokens per second)\n","llama_print_timings: prompt eval time =     459.83 ms /    14 tokens (   32.85 ms per token,    30.45 tokens per second)\n","llama_print_timings:        eval time =   30837.09 ms /   392 runs   (   78.67 ms per token,    12.71 tokens per second)\n","llama_print_timings:       total time =   33446.63 ms /   406 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     575.67 ms /   337 runs   (    1.71 ms per token,   585.41 tokens per second)\n","llama_print_timings: prompt eval time =     451.19 ms /    13 tokens (   34.71 ms per token,    28.81 tokens per second)\n","llama_print_timings:        eval time =   26121.85 ms /   336 runs   (   77.74 ms per token,    12.86 tokens per second)\n","llama_print_timings:       total time =   28392.71 ms /   349 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     601.08 ms /   350 runs   (    1.72 ms per token,   582.29 tokens per second)\n","llama_print_timings: prompt eval time =     335.10 ms /    10 tokens (   33.51 ms per token,    29.84 tokens per second)\n","llama_print_timings:        eval time =   27556.33 ms /   349 runs   (   78.96 ms per token,    12.66 tokens per second)\n","llama_print_timings:       total time =   29804.83 ms /   359 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     233.48 ms /   138 runs   (    1.69 ms per token,   591.05 tokens per second)\n","llama_print_timings: prompt eval time =     443.53 ms /    13 tokens (   34.12 ms per token,    29.31 tokens per second)\n","llama_print_timings:        eval time =   10680.14 ms /   137 runs   (   77.96 ms per token,    12.83 tokens per second)\n","llama_print_timings:       total time =   11836.19 ms /   150 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     235.00 ms /   139 runs   (    1.69 ms per token,   591.48 tokens per second)\n","llama_print_timings: prompt eval time =     445.01 ms /    14 tokens (   31.79 ms per token,    31.46 tokens per second)\n","llama_print_timings:        eval time =   10842.64 ms /   138 runs   (   78.57 ms per token,    12.73 tokens per second)\n","llama_print_timings:       total time =   12007.50 ms /   152 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     589.50 ms /   349 runs   (    1.69 ms per token,   592.03 tokens per second)\n","llama_print_timings: prompt eval time =     452.51 ms /    14 tokens (   32.32 ms per token,    30.94 tokens per second)\n","llama_print_timings:        eval time =   26872.99 ms /   348 runs   (   77.22 ms per token,    12.95 tokens per second)\n","llama_print_timings:       total time =   29203.04 ms /   362 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     631.55 ms /   373 runs   (    1.69 ms per token,   590.61 tokens per second)\n","llama_print_timings: prompt eval time =     341.05 ms /    12 tokens (   28.42 ms per token,    35.19 tokens per second)\n","llama_print_timings:        eval time =   29168.61 ms /   372 runs   (   78.41 ms per token,    12.75 tokens per second)\n","llama_print_timings:       total time =   31513.42 ms /   384 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     235.04 ms /   139 runs   (    1.69 ms per token,   591.38 tokens per second)\n","llama_print_timings: prompt eval time =     461.19 ms /    14 tokens (   32.94 ms per token,    30.36 tokens per second)\n","llama_print_timings:        eval time =   10489.81 ms /   138 runs   (   76.01 ms per token,    13.16 tokens per second)\n","llama_print_timings:       total time =   11676.68 ms /   152 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     514.56 ms /   305 runs   (    1.69 ms per token,   592.73 tokens per second)\n","llama_print_timings: prompt eval time =     472.62 ms /    14 tokens (   33.76 ms per token,    29.62 tokens per second)\n","llama_print_timings:        eval time =   23682.38 ms /   304 runs   (   77.90 ms per token,    12.84 tokens per second)\n","llama_print_timings:       total time =   25789.84 ms /   318 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     567.42 ms /   332 runs   (    1.71 ms per token,   585.11 tokens per second)\n","llama_print_timings: prompt eval time =     444.95 ms /    14 tokens (   31.78 ms per token,    31.46 tokens per second)\n","llama_print_timings:        eval time =   25580.92 ms /   331 runs   (   77.28 ms per token,    12.94 tokens per second)\n","llama_print_timings:       total time =   27816.68 ms /   345 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     669.77 ms /   402 runs   (    1.67 ms per token,   600.21 tokens per second)\n","llama_print_timings: prompt eval time =     458.56 ms /    15 tokens (   30.57 ms per token,    32.71 tokens per second)\n","llama_print_timings:        eval time =   31839.20 ms /   401 runs   (   79.40 ms per token,    12.59 tokens per second)\n","llama_print_timings:       total time =   34445.19 ms /   416 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     681.77 ms /   393 runs   (    1.73 ms per token,   576.44 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =   30625.45 ms /   393 runs   (   77.93 ms per token,    12.83 tokens per second)\n","llama_print_timings:       total time =   32798.43 ms /   394 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     551.81 ms /   325 runs   (    1.70 ms per token,   588.97 tokens per second)\n","llama_print_timings: prompt eval time =     332.71 ms /     9 tokens (   36.97 ms per token,    27.05 tokens per second)\n","llama_print_timings:        eval time =   25845.00 ms /   324 runs   (   79.77 ms per token,    12.54 tokens per second)\n","llama_print_timings:       total time =   27891.34 ms /   333 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     664.63 ms /   393 runs   (    1.69 ms per token,   591.31 tokens per second)\n","llama_print_timings: prompt eval time =     459.21 ms /    14 tokens (   32.80 ms per token,    30.49 tokens per second)\n","llama_print_timings:        eval time =   30224.39 ms /   392 runs   (   77.10 ms per token,    12.97 tokens per second)\n","llama_print_timings:       total time =   32803.50 ms /   406 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     608.10 ms /   356 runs   (    1.71 ms per token,   585.43 tokens per second)\n","llama_print_timings: prompt eval time =     340.83 ms /    12 tokens (   28.40 ms per token,    35.21 tokens per second)\n","llama_print_timings:        eval time =   28117.80 ms /   355 runs   (   79.21 ms per token,    12.63 tokens per second)\n","llama_print_timings:       total time =   30388.86 ms /   367 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     533.33 ms /   314 runs   (    1.70 ms per token,   588.76 tokens per second)\n","llama_print_timings: prompt eval time =     463.47 ms /    16 tokens (   28.97 ms per token,    34.52 tokens per second)\n","llama_print_timings:        eval time =   24242.45 ms /   313 runs   (   77.45 ms per token,    12.91 tokens per second)\n","llama_print_timings:       total time =   26383.30 ms /   329 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     588.79 ms /   349 runs   (    1.69 ms per token,   592.74 tokens per second)\n","llama_print_timings: prompt eval time =     449.04 ms /    14 tokens (   32.07 ms per token,    31.18 tokens per second)\n","llama_print_timings:        eval time =   27095.25 ms /   348 runs   (   77.86 ms per token,    12.84 tokens per second)\n","llama_print_timings:       total time =   29412.01 ms /   362 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     563.06 ms /   332 runs   (    1.70 ms per token,   589.64 tokens per second)\n","llama_print_timings: prompt eval time =     448.91 ms /    15 tokens (   29.93 ms per token,    33.41 tokens per second)\n","llama_print_timings:        eval time =   25915.89 ms /   331 runs   (   78.30 ms per token,    12.77 tokens per second)\n","llama_print_timings:       total time =   28151.27 ms /   346 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     630.22 ms /   373 runs   (    1.69 ms per token,   591.86 tokens per second)\n","llama_print_timings: prompt eval time =     366.45 ms /    12 tokens (   30.54 ms per token,    32.75 tokens per second)\n","llama_print_timings:        eval time =   28835.49 ms /   372 runs   (   77.51 ms per token,    12.90 tokens per second)\n","llama_print_timings:       total time =   31202.38 ms /   384 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     590.42 ms /   349 runs   (    1.69 ms per token,   591.10 tokens per second)\n","llama_print_timings: prompt eval time =     452.74 ms /    14 tokens (   32.34 ms per token,    30.92 tokens per second)\n","llama_print_timings:        eval time =   27529.71 ms /   348 runs   (   79.11 ms per token,    12.64 tokens per second)\n","llama_print_timings:       total time =   29873.52 ms /   362 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     616.19 ms /   361 runs   (    1.71 ms per token,   585.86 tokens per second)\n","llama_print_timings: prompt eval time =     477.01 ms /    15 tokens (   31.80 ms per token,    31.45 tokens per second)\n","llama_print_timings:        eval time =   27910.06 ms /   360 runs   (   77.53 ms per token,    12.90 tokens per second)\n","llama_print_timings:       total time =   30367.09 ms /   375 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     715.65 ms /   416 runs   (    1.72 ms per token,   581.29 tokens per second)\n","llama_print_timings: prompt eval time =     448.77 ms /    13 tokens (   34.52 ms per token,    28.97 tokens per second)\n","llama_print_timings:        eval time =   32580.10 ms /   415 runs   (   78.51 ms per token,    12.74 tokens per second)\n","llama_print_timings:       total time =   35345.63 ms /   428 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     522.56 ms /   305 runs   (    1.71 ms per token,   583.66 tokens per second)\n","llama_print_timings: prompt eval time =     458.81 ms /    14 tokens (   32.77 ms per token,    30.51 tokens per second)\n","llama_print_timings:        eval time =   23785.38 ms /   304 runs   (   78.24 ms per token,    12.78 tokens per second)\n","llama_print_timings:       total time =   25906.19 ms /   318 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     521.18 ms /   303 runs   (    1.72 ms per token,   581.37 tokens per second)\n","llama_print_timings: prompt eval time =     338.28 ms /    11 tokens (   30.75 ms per token,    32.52 tokens per second)\n","llama_print_timings:        eval time =   23248.98 ms /   302 runs   (   76.98 ms per token,    12.99 tokens per second)\n","llama_print_timings:       total time =   25240.70 ms /   313 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     597.38 ms /   349 runs   (    1.71 ms per token,   584.22 tokens per second)\n","llama_print_timings: prompt eval time =     460.66 ms /    14 tokens (   32.90 ms per token,    30.39 tokens per second)\n","llama_print_timings:        eval time =   27513.92 ms /   348 runs   (   79.06 ms per token,    12.65 tokens per second)\n","llama_print_timings:       total time =   29886.25 ms /   362 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     616.21 ms /   358 runs   (    1.72 ms per token,   580.98 tokens per second)\n","llama_print_timings: prompt eval time =     437.25 ms /    13 tokens (   33.63 ms per token,    29.73 tokens per second)\n","llama_print_timings:        eval time =   27627.35 ms /   357 runs   (   77.39 ms per token,    12.92 tokens per second)\n","llama_print_timings:       total time =   30030.45 ms /   370 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     565.89 ms /   332 runs   (    1.70 ms per token,   586.69 tokens per second)\n","llama_print_timings: prompt eval time =     464.98 ms /    13 tokens (   35.77 ms per token,    27.96 tokens per second)\n","llama_print_timings:        eval time =   25514.76 ms /   331 runs   (   77.08 ms per token,    12.97 tokens per second)\n","llama_print_timings:       total time =   27781.68 ms /   344 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     616.44 ms /   358 runs   (    1.72 ms per token,   580.76 tokens per second)\n","llama_print_timings: prompt eval time =     469.67 ms /    13 tokens (   36.13 ms per token,    27.68 tokens per second)\n","llama_print_timings:        eval time =   27890.76 ms /   357 runs   (   78.13 ms per token,    12.80 tokens per second)\n","llama_print_timings:       total time =   30320.43 ms /   370 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     557.82 ms /   324 runs   (    1.72 ms per token,   580.84 tokens per second)\n","llama_print_timings: prompt eval time =     458.28 ms /    13 tokens (   35.25 ms per token,    28.37 tokens per second)\n","llama_print_timings:        eval time =   24992.36 ms /   323 runs   (   77.38 ms per token,    12.92 tokens per second)\n","llama_print_timings:       total time =   27225.67 ms /   336 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     595.57 ms /   350 runs   (    1.70 ms per token,   587.68 tokens per second)\n","llama_print_timings: prompt eval time =     465.48 ms /    15 tokens (   31.03 ms per token,    32.22 tokens per second)\n","llama_print_timings:        eval time =   26963.01 ms /   349 runs   (   77.26 ms per token,    12.94 tokens per second)\n","llama_print_timings:       total time =   29337.35 ms /   364 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     670.90 ms /   393 runs   (    1.71 ms per token,   585.78 tokens per second)\n","llama_print_timings: prompt eval time =     450.40 ms /    14 tokens (   32.17 ms per token,    31.08 tokens per second)\n","llama_print_timings:        eval time =   30804.43 ms /   392 runs   (   78.58 ms per token,    12.73 tokens per second)\n","llama_print_timings:       total time =   33416.99 ms /   406 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     517.79 ms /   305 runs   (    1.70 ms per token,   589.04 tokens per second)\n","llama_print_timings: prompt eval time =     458.91 ms /    14 tokens (   32.78 ms per token,    30.51 tokens per second)\n","llama_print_timings:        eval time =   23657.38 ms /   304 runs   (   77.82 ms per token,    12.85 tokens per second)\n","llama_print_timings:       total time =   25769.36 ms /   318 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     552.85 ms /   324 runs   (    1.71 ms per token,   586.05 tokens per second)\n","llama_print_timings: prompt eval time =     447.15 ms /    13 tokens (   34.40 ms per token,    29.07 tokens per second)\n","llama_print_timings:        eval time =   24935.17 ms /   323 runs   (   77.20 ms per token,    12.95 tokens per second)\n","llama_print_timings:       total time =   27140.48 ms /   336 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     592.85 ms /   350 runs   (    1.69 ms per token,   590.37 tokens per second)\n","llama_print_timings: prompt eval time =     354.94 ms /    10 tokens (   35.49 ms per token,    28.17 tokens per second)\n","llama_print_timings:        eval time =   27774.70 ms /   349 runs   (   79.58 ms per token,    12.57 tokens per second)\n","llama_print_timings:       total time =   30027.43 ms /   359 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     219.29 ms /   130 runs   (    1.69 ms per token,   592.82 tokens per second)\n","llama_print_timings: prompt eval time =     458.78 ms /    16 tokens (   28.67 ms per token,    34.87 tokens per second)\n","llama_print_timings:        eval time =   10116.16 ms /   129 runs   (   78.42 ms per token,    12.75 tokens per second)\n","llama_print_timings:       total time =   11244.66 ms /   145 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     599.44 ms /   356 runs   (    1.68 ms per token,   593.89 tokens per second)\n","llama_print_timings: prompt eval time =     342.01 ms /    12 tokens (   28.50 ms per token,    35.09 tokens per second)\n","llama_print_timings:        eval time =   27578.51 ms /   355 runs   (   77.69 ms per token,    12.87 tokens per second)\n","llama_print_timings:       total time =   29824.06 ms /   367 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     223.27 ms /   130 runs   (    1.72 ms per token,   582.24 tokens per second)\n","llama_print_timings: prompt eval time =     458.65 ms /    16 tokens (   28.67 ms per token,    34.88 tokens per second)\n","llama_print_timings:        eval time =   10046.58 ms /   129 runs   (   77.88 ms per token,    12.84 tokens per second)\n","llama_print_timings:       total time =   11187.92 ms /   145 tokens\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =    1035.39 ms\n","llama_print_timings:      sample time =     540.39 ms /   314 runs   (    1.72 ms per token,   581.06 tokens per second)\n","llama_print_timings: prompt eval time =     465.84 ms /    16 tokens (   29.12 ms per token,    34.35 tokens per second)\n","llama_print_timings:        eval time =   24260.96 ms /   313 runs   (   77.51 ms per token,    12.90 tokens per second)\n","llama_print_timings:       total time =   26438.94 ms /   329 tokens\n"]}],"source":["# Apply the LLaMA model to each review and generate a sentiment prediction\n","tqdm.pandas()\n","data_4['model_response'] = data_4['CleanedReview'].progress_apply(\n","    lambda x: generate_llama_response_2(instruction_2, x)\n",")"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1751488235284,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"mCn25HcL6XF7","outputId":"e0d294da-1664-423b-afe3-82a0a8e85403"},"outputs":[{"output_type":"stream","name":"stdout","text":["A page-turner with a powerful message.\n"]}],"source":["i = 1\n","print(data_4.loc[i, 'CleanedReview'])"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1751488237466,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"Vt7c7nMY1i8i","outputId":"c941cac1-6ca6-49dc-a587-e4a048396486"},"outputs":[{"output_type":"stream","name":"stdout","text":["Empty DataFrame\n","Columns: [ReviewText, Sentiment, CleanedReview, model_response]\n","Index: []\n"]}],"source":["# Identify rows where the model_response is an empty JSON object\n","empty_json_rows = data_4[data_4['model_response'].astype(str).str.strip() == '{}']\n","print(empty_json_rows)"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1751488239499,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"Mtasc6Xs6da0","outputId":"4b117d27-1467-4b47-ca3e-c41ba9588461"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sure, I'd be happy to help you analyze the book review! Here's the JSON object with my predictions:\n","\n","{\n","\"Overall Sentiment\": \"Positive\",\n","\"Writing Style\": \"Positive\",\n","\"Emotional Impact\": \"Positive\",\n","\"Pacing\": [\"fast-paced\"],\n","\"Ending\": [\"satisfying\"],\n","\"Response\": \"Thank you for your review! We're glad you enjoyed the book and found it to be a page-turner with a powerful message. If you have any suggestions for improvement, we would love to hear them.\"\n","}\n","\n","Here's how I arrived at these predictions:\n","\n","1. Overall Sentiment: The review expresses a positive sentiment towards the book, so I classified it as \"Positive\".\n","2. Writing Style: The reviewer describes the book as a \"page-turner\", which suggests that the writing style is engaging and effective. I classified this aspect as \"Positive\".\n","3. Emotional Impact: The reviewer mentions that the book has a \"powerful message\", which implies that it had an emotional impact on them. I classified this aspect as \"Positive\".\n","4. Pacing: The reviewer mentions that the book is \"fast-paced\", which suggests that the pacing is quick and engaging. I classified this aspect as \"Positive\".\n","5. Ending: The reviewer describes the ending as \"satisfying\", which suggests that it is a satisfying conclusion to the story. I classified this aspect as \"Positive\".\n","6. Response: I responded with a thank you and a statement that we're glad they enjoyed the book, and we would love to hear any suggestions for improvement.\n","\n","I hope this helps! Let me know if you have any other questions.\n"]}],"source":["print(data_4.loc[i, 'model_response'])"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1751488242091,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"262Pj92VEgdU","outputId":"1db563f4-edc3-4ed5-eb9a-2dd15306ab60"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    {'Overall Sentiment': 'Negative', 'Writing Sty...\n","1    {'Overall Sentiment': 'Positive', 'Writing Sty...\n","2    {'Overall Sentiment': 'Positive', 'Writing Sty...\n","3    {'Overall Sentiment': 'Positive', 'Writing Sty...\n","4    {'Overall Sentiment': 'Neutral', 'Writing Styl...\n","Name: model_response_parsed, dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model_response_parsed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'Overall Sentiment': 'Negative', 'Writing Sty...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'Overall Sentiment': 'Positive', 'Writing Sty...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'Overall Sentiment': 'Positive', 'Writing Sty...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'Overall Sentiment': 'Positive', 'Writing Sty...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'Overall Sentiment': 'Neutral', 'Writing Styl...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":42}],"source":["# applying the function to the model response\n","data_4['model_response_parsed'] = data_4['model_response'].apply(extract_json_data)\n","data_4['model_response_parsed'].head()"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1751484525415,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"B7hm3nROEbMu","outputId":"d18f1c63-d8a3-4625-b8bd-8f7181a77e61"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: [ReviewText, Sentiment, CleanedReview, model_response, model_response_parsed]\n","Index: []"],"text/html":["\n","  <div id=\"df-636044f9-4bc8-4009-97bd-078eb5fd4e16\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ReviewText</th>\n","      <th>Sentiment</th>\n","      <th>CleanedReview</th>\n","      <th>model_response</th>\n","      <th>model_response_parsed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-636044f9-4bc8-4009-97bd-078eb5fd4e16')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-636044f9-4bc8-4009-97bd-078eb5fd4e16 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-636044f9-4bc8-4009-97bd-078eb5fd4e16');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"Out of range float values are not JSON compliant: nan"}},"metadata":{},"execution_count":29}],"source":["# Filter rows where the parsed JSON result is an empty dictionary\n","data_4[data_4.model_response_parsed == {}]"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1751488246825,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"v21yWILmEpSs","outputId":"2830e26f-88a8-4b9f-e13b-21a76fcc49ff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  Overall Sentiment Writing Style Emotional Impact  \\\n","0          Negative      Negative         Negative   \n","1          Positive      Positive         Positive   \n","2          Positive      Positive         Positive   \n","3          Positive      Positive         Positive   \n","4           Neutral       Neutral          Neutral   \n","\n","                         Pacing                        Ending  \\\n","0                            []                            []   \n","1                  [fast-paced]                  [satisfying]   \n","2                            []                            []   \n","3  [heartwarming and inspiring]  [heartwarming and inspiring]   \n","4                            []                            []   \n","\n","                                            Response  \n","0  Thank you for taking the time to share your fe...  \n","1  Thank you for your review! We're glad you enjo...  \n","2  Thank you for your positive review! We're glad...  \n","3  Thank you for your positive review! We're glad...  \n","4  Thank you for taking the time to share your th...  "],"text/html":["\n","  <div id=\"df-57c8d401-4f88-4039-89ef-1e6f1d73198f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Overall Sentiment</th>\n","      <th>Writing Style</th>\n","      <th>Emotional Impact</th>\n","      <th>Pacing</th>\n","      <th>Ending</th>\n","      <th>Response</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for taking the time to share your fe...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>[fast-paced]</td>\n","      <td>[satisfying]</td>\n","      <td>Thank you for your review! We're glad you enjo...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for your positive review! We're glad...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>[heartwarming and inspiring]</td>\n","      <td>[heartwarming and inspiring]</td>\n","      <td>Thank you for your positive review! We're glad...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for taking the time to share your th...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57c8d401-4f88-4039-89ef-1e6f1d73198f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-57c8d401-4f88-4039-89ef-1e6f1d73198f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-57c8d401-4f88-4039-89ef-1e6f1d73198f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-9547c5c4-ea3e-458a-ae2c-2a72f82203b8\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9547c5c4-ea3e-458a-ae2c-2a72f82203b8')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-9547c5c4-ea3e-458a-ae2c-2a72f82203b8 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"model_response_parsed_df_4","summary":"{\n  \"name\": \"model_response_parsed_df_4\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Overall Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Negative\",\n          \"Positive\",\n          \"Neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Writing Style\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Positive\",\n          \"Decent\",\n          \"Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Emotional Impact\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Positive\",\n          \"Mediocre\",\n          \"Neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pacing\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ending\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Response\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Thank you for taking the time to share your thoughts on this book. While it's disappointing to hear that it didn't stand out as remarkable, your feedback is valuable to us. If you have any specific suggestions on what could have improved your experience, we would love to hear them.\",\n          \"Thank you for taking the time to share your feedback. Sorry to hear that you found the book uninspiring and boring. Your input is valuable to us and will be reviewed by our team.\",\n          \"Thank you for taking the time to share your thoughts on this book. We appreciate your feedback and would love to hear more about what could have improved your experience.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":43}],"source":["# Each key in the JSON becomes a column, and each value becomes a row cell.\n","model_response_parsed_df_4 = pd.json_normalize(data_4['model_response_parsed'])\n","model_response_parsed_df_4.head()"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":56,"status":"ok","timestamp":1751488250841,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"uqjAltWGEw27","outputId":"0e1660c8-711b-4f97-fc91-c6caa033670b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           ReviewText  Sentiment  \\\n","0               Review #1: Highly disappointing read.          0   \n","1   Review #2: A page-turner with a powerful message.          2   \n","2           Review #3: A masterpiece of storytelling.          2   \n","3         Review #4: Heartwarming and inspiring read.          2   \n","4         Review #5: Neither good nor bad, just fine.          1   \n","5              Review #6: Absolutely loved this book!          2   \n","6             Review #7: Overhyped and underwhelming.          0   \n","7   Review #8: Some parts were slow, overall reada...          1   \n","8     Review #9: Had its moments, but not remarkable.          1   \n","9   Review #10: Neutral feelings, not very impactful.          1   \n","10  Review #11: Plain narrative, suitable for casu...          1   \n","11          Review #12: Struggled to stay interested.          0   \n","12   Review #13: Had its moments, but not remarkable.          1   \n","13       Review #14: Neither good nor bad, just fine.          1   \n","14  Review #15: Terrible writing, couldn't finish it.          0   \n","15  Review #16: Plain narrative, suitable for casu...          1   \n","\n","                                    CleanedReview  \\\n","0                      Highly disappointing read.   \n","1          A page-turner with a powerful message.   \n","2                  A masterpiece of storytelling.   \n","3                Heartwarming and inspiring read.   \n","4                Neither good nor bad, just fine.   \n","5                     Absolutely loved this book!   \n","6                    Overhyped and underwhelming.   \n","7         Some parts were slow, overall readable.   \n","8            Had its moments, but not remarkable.   \n","9           Neutral feelings, not very impactful.   \n","10  Plain narrative, suitable for casual reading.   \n","11                  Struggled to stay interested.   \n","12           Had its moments, but not remarkable.   \n","13               Neither good nor bad, just fine.   \n","14          Terrible writing, couldn't finish it.   \n","15  Plain narrative, suitable for casual reading.   \n","\n","                                       model_response  \\\n","0   Sure, I'd be happy to help you analyze the boo...   \n","1   Sure, I'd be happy to help you analyze the boo...   \n","2   Sure, I'd be happy to help you analyze the boo...   \n","3   Sure, I'd be happy to help you analyze the boo...   \n","4   Sure, I'd be happy to help you analyze the boo...   \n","5   Sure, I'd be happy to help you analyze the boo...   \n","6   Sure, I'd be happy to help you analyze the boo...   \n","7   Sure, I'd be happy to help you analyze the boo...   \n","8   Sure, I'd be happy to help you analyze the boo...   \n","9   Sure, I'd be happy to help you analyze the boo...   \n","10  Sure, I'd be happy to help you analyze the boo...   \n","11  Sure, I'd be happy to help you analyze the boo...   \n","12  Sure, I'd be happy to help you analyze the boo...   \n","13  Sure, I'd be happy to help you analyze the boo...   \n","14  Sure, I'd be happy to help you with that! Here...   \n","15  Sure, I'd be happy to help you analyze the boo...   \n","\n","                                model_response_parsed Overall Sentiment  \\\n","0   {'Overall Sentiment': 'Negative', 'Writing Sty...          Negative   \n","1   {'Overall Sentiment': 'Positive', 'Writing Sty...          Positive   \n","2   {'Overall Sentiment': 'Positive', 'Writing Sty...          Positive   \n","3   {'Overall Sentiment': 'Positive', 'Writing Sty...          Positive   \n","4   {'Overall Sentiment': 'Neutral', 'Writing Styl...           Neutral   \n","5   {'Overall Sentiment': 'Positive', 'Writing Sty...          Positive   \n","6   {'Overall Sentiment': 'Negative', 'Writing Sty...          Negative   \n","7   {'Overall Sentiment': 'Neutral', 'Writing Styl...           Neutral   \n","8   {'Overall Sentiment': 'Neutral', 'Writing Styl...           Neutral   \n","9   {'Overall Sentiment': 'Neutral', 'Writing Styl...           Neutral   \n","10  {'Overall Sentiment': 'Neutral', 'Writing Styl...           Neutral   \n","11  {'Overall Sentiment': 'Negative', 'Writing Sty...          Negative   \n","12  {'Overall Sentiment': 'Neutral', 'Writing Styl...           Neutral   \n","13  {'Overall Sentiment': 'Neutral', 'Writing Styl...           Neutral   \n","14  {'Overall Sentiment': 'Negative', 'Writing Sty...          Negative   \n","15  {'Overall Sentiment': 'Neutral', 'Writing Styl...           Neutral   \n","\n","   Writing Style Emotional Impact                        Pacing  \\\n","0       Negative         Negative                            []   \n","1       Positive         Positive                  [fast-paced]   \n","2       Positive         Positive                            []   \n","3       Positive         Positive  [heartwarming and inspiring]   \n","4        Neutral          Neutral                            []   \n","5       Positive         Positive                       [liked]   \n","6       Negative         Negative               [underwhelming]   \n","7        Neutral          Neutral              [not applicable]   \n","8        Neutral          Neutral                            []   \n","9        Neutral          Neutral                            []   \n","10       Neutral          Neutral                            []   \n","11      Negative         Negative                    [disliked]   \n","12       Neutral          Neutral                            []   \n","13       Neutral          Neutral                            []   \n","14      Negative   Not Applicable                            []   \n","15       Neutral          Neutral                            []   \n","\n","                          Ending  \\\n","0                             []   \n","1                   [satisfying]   \n","2                             []   \n","3   [heartwarming and inspiring]   \n","4                             []   \n","5                        [liked]   \n","6                [underwhelming]   \n","7               [not applicable]   \n","8                             []   \n","9                             []   \n","10                            []   \n","11                    [disliked]   \n","12                            []   \n","13                            []   \n","14                            []   \n","15                            []   \n","\n","                                             Response  \n","0   Thank you for taking the time to share your fe...  \n","1   Thank you for your review! We're glad you enjo...  \n","2   Thank you for your positive review! We're glad...  \n","3   Thank you for your positive review! We're glad...  \n","4   Thank you for taking the time to share your th...  \n","5   Thank you so much for your review! We're glad ...  \n","6   Sorry to hear that you found the book overhype...  \n","7   Thank you for your review! We appreciate your ...  \n","8   Thank you for taking the time to share your th...  \n","9   Thank you for taking the time to share your th...  \n","10  Thank you for taking the time to share your th...  \n","11  Thank you for taking the time to share your fe...  \n","12  Thank you for taking the time to share your th...  \n","13  Thank you for taking the time to share your th...  \n","14  Thank you for taking the time to share your fe...  \n","15  Thank you for taking the time to share your th...  "],"text/html":["\n","  <div id=\"df-a4b5e790-f4b8-4c28-a670-e4eb09a35b8a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ReviewText</th>\n","      <th>Sentiment</th>\n","      <th>CleanedReview</th>\n","      <th>model_response</th>\n","      <th>model_response_parsed</th>\n","      <th>Overall Sentiment</th>\n","      <th>Writing Style</th>\n","      <th>Emotional Impact</th>\n","      <th>Pacing</th>\n","      <th>Ending</th>\n","      <th>Response</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Review #1: Highly disappointing read.</td>\n","      <td>0</td>\n","      <td>Highly disappointing read.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Negative', 'Writing Sty...</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for taking the time to share your fe...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Review #2: A page-turner with a powerful message.</td>\n","      <td>2</td>\n","      <td>A page-turner with a powerful message.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Positive', 'Writing Sty...</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>[fast-paced]</td>\n","      <td>[satisfying]</td>\n","      <td>Thank you for your review! We're glad you enjo...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Review #3: A masterpiece of storytelling.</td>\n","      <td>2</td>\n","      <td>A masterpiece of storytelling.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Positive', 'Writing Sty...</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for your positive review! We're glad...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Review #4: Heartwarming and inspiring read.</td>\n","      <td>2</td>\n","      <td>Heartwarming and inspiring read.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Positive', 'Writing Sty...</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>[heartwarming and inspiring]</td>\n","      <td>[heartwarming and inspiring]</td>\n","      <td>Thank you for your positive review! We're glad...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Review #5: Neither good nor bad, just fine.</td>\n","      <td>1</td>\n","      <td>Neither good nor bad, just fine.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Neutral', 'Writing Styl...</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for taking the time to share your th...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Review #6: Absolutely loved this book!</td>\n","      <td>2</td>\n","      <td>Absolutely loved this book!</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Positive', 'Writing Sty...</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>[liked]</td>\n","      <td>[liked]</td>\n","      <td>Thank you so much for your review! We're glad ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Review #7: Overhyped and underwhelming.</td>\n","      <td>0</td>\n","      <td>Overhyped and underwhelming.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Negative', 'Writing Sty...</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>[underwhelming]</td>\n","      <td>[underwhelming]</td>\n","      <td>Sorry to hear that you found the book overhype...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Review #8: Some parts were slow, overall reada...</td>\n","      <td>1</td>\n","      <td>Some parts were slow, overall readable.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Neutral', 'Writing Styl...</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>[not applicable]</td>\n","      <td>[not applicable]</td>\n","      <td>Thank you for your review! We appreciate your ...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Review #9: Had its moments, but not remarkable.</td>\n","      <td>1</td>\n","      <td>Had its moments, but not remarkable.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Neutral', 'Writing Styl...</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for taking the time to share your th...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Review #10: Neutral feelings, not very impactful.</td>\n","      <td>1</td>\n","      <td>Neutral feelings, not very impactful.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Neutral', 'Writing Styl...</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for taking the time to share your th...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Review #11: Plain narrative, suitable for casu...</td>\n","      <td>1</td>\n","      <td>Plain narrative, suitable for casual reading.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Neutral', 'Writing Styl...</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for taking the time to share your th...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Review #12: Struggled to stay interested.</td>\n","      <td>0</td>\n","      <td>Struggled to stay interested.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Negative', 'Writing Sty...</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>[disliked]</td>\n","      <td>[disliked]</td>\n","      <td>Thank you for taking the time to share your fe...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Review #13: Had its moments, but not remarkable.</td>\n","      <td>1</td>\n","      <td>Had its moments, but not remarkable.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Neutral', 'Writing Styl...</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for taking the time to share your th...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Review #14: Neither good nor bad, just fine.</td>\n","      <td>1</td>\n","      <td>Neither good nor bad, just fine.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Neutral', 'Writing Styl...</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for taking the time to share your th...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Review #15: Terrible writing, couldn't finish it.</td>\n","      <td>0</td>\n","      <td>Terrible writing, couldn't finish it.</td>\n","      <td>Sure, I'd be happy to help you with that! Here...</td>\n","      <td>{'Overall Sentiment': 'Negative', 'Writing Sty...</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Not Applicable</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for taking the time to share your fe...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Review #16: Plain narrative, suitable for casu...</td>\n","      <td>1</td>\n","      <td>Plain narrative, suitable for casual reading.</td>\n","      <td>Sure, I'd be happy to help you analyze the boo...</td>\n","      <td>{'Overall Sentiment': 'Neutral', 'Writing Styl...</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for taking the time to share your th...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4b5e790-f4b8-4c28-a670-e4eb09a35b8a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a4b5e790-f4b8-4c28-a670-e4eb09a35b8a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a4b5e790-f4b8-4c28-a670-e4eb09a35b8a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-2dcce6cc-e225-438a-878b-93fb7b2d8f30\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2dcce6cc-e225-438a-878b-93fb7b2d8f30')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-2dcce6cc-e225-438a-878b-93fb7b2d8f30 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data_with_parsed_model_output_4","summary":"{\n  \"name\": \"data_with_parsed_model_output_4\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"ReviewText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Review #84: Uninspiring and boring.\",\n          \"Review #54: The best book I've read this year.\",\n          \"Review #71: Neither good nor bad, just fine.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CleanedReview\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"A waste of time.\",\n          \"Uninspiring and boring.\",\n          \"Poor character development.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_response\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"Sure, I'd be happy to help you analyze the book review! Here's the JSON object with my predictions:\\n\\n{\\n\\\"Overall Sentiment\\\": \\\"Positive\\\",\\n\\\"Writing Style\\\": \\\"Positive\\\",\\n\\\"Emotional Impact\\\": \\\"Positive\\\",\\n\\\"Pacing\\\": [\\\"fast-paced\\\"],\\n\\\"Ending\\\": [\\\"satisfying\\\"],\\n\\\"Response\\\": \\\"Thank you for your review! We're glad you enjoyed the book and found it to be a page-turner with a powerful message. If you have any suggestions for improvement, we would love to hear them.\\\"\\n}\\n\\nHere's how I arrived at these predictions:\\n\\n1. Overall Sentiment: The review expresses a positive sentiment towards the book, so I classified it as \\\"Positive\\\".\\n2. Writing Style: The reviewer describes the book as a \\\"page-turner\\\", which suggests that the writing style is engaging and effective. I classified this aspect as \\\"Positive\\\".\\n3. Emotional Impact: The reviewer mentions that the book has a \\\"powerful message\\\", which implies that it had an emotional impact on them. I classified this aspect as \\\"Positive\\\".\\n4. Pacing: The reviewer mentions that the book is \\\"fast-paced\\\", which suggests that the pacing is quick and engaging. I classified this aspect as \\\"Positive\\\".\\n5. Ending: The reviewer describes the ending as \\\"satisfying\\\", which suggests that it is a satisfying conclusion to the story. I classified this aspect as \\\"Positive\\\".\\n6. Response: I responded with a thank you and an invitation for the reviewer to share any suggestions for improvement.\\n\\nI hope this helps! Let me know if you have any other questions.\",\n          \"Sure, I'd be happy to help you analyze the book review! Here's the output you requested:\\n\\n{\\n\\\"Overall Sentiment\\\": \\\"Negative\\\",\\n\\\"Writing Style\\\": \\\"Negative\\\",\\n\\\"Emotional Impact\\\": \\\"Negative\\\",\\n\\\"Pacing\\\": [\\\"not applicable\\\"],\\n\\\"Ending\\\": [\\\"not applicable\\\"],\\n\\\"Response\\\": \\\"Thank you for taking the time to share your feedback. Sorry to hear that you found the book uninspiring and boring. Your input is valuable to us and will be reviewed by our team.\\\"\\n}\\n\\nHere's how I arrived at each of the sentiment classifications and feature assessments:\\n\\n1. Overall Sentiment: The review expresses a negative sentiment towards the book, so I classified the overall sentiment as \\\"Negative\\\".\\n2. Writing Style: The reviewer describes the book as \\\"uninspiring and boring\\\", which suggests that the writing style did not engage or captivate them. I classified the writing style as \\\"Negative\\\".\\n3. Emotional Impact: The review does not mention any emotional impact or resonance from the book. I classified the emotional impact as \\\"Not Applicable\\\".\\n4. Pacing: The reviewer does not mention the pacing of the book, so I classified the pacing as \\\"Not Applicable\\\".\\n5. Ending: The reviewer does not mention the ending of the book, so I classified the ending as \\\"Not Applicable\\\".\\n6. Liked or Disliked Features: Based on the review, the reviewer did not like the book. I identified the following features as disliked:\\n\\t* Writing style\\n\\t* Emotional impact\\n\\nI hope this helps! Let me know if you have any further questions or if there's anything else I can assist you with.\",\n          \"Sure, I'd be happy to help you analyze the book review! Here's the information you requested:\\n\\n{\\n\\\"Overall Sentiment\\\": \\\"Negative\\\",\\n\\\"Writing Style\\\": \\\"Negative\\\",\\n\\\"Emotional Impact\\\": \\\"Negative\\\",\\n\\\"Pacing\\\": [\\\"disliked\\\"],\\n\\\"Ending\\\": [\\\"disliked\\\"],\\n\\\"Response\\\": \\\"Thank you for taking the time to share your feedback. Sorry to hear that you found the character development to be poor. We will review your feedback and use it to improve our future books.\\\"\\n}\\n\\nHere's how I arrived at these answers:\\n\\n1. Overall Sentiment: The review expresses a negative sentiment towards the book, so I classified the overall sentiment as \\\"Negative\\\".\\n2. Writing Style: The reviewer mentions \\\"poor character development\\\", which suggests that the writing style did not effectively convey the characters, so I classified the writing style as \\\"Negative\\\".\\n3. Emotional Impact: The reviewer does not mention any emotional impact, so I classified the emotional impact as \\\"Not Applicable\\\".\\n4. Pacing: The reviewer mentions that the pacing was poor, so I classified the pacing as \\\"disliked\\\".\\n5. Ending: The reviewer does not mention the ending, so I classified the ending as \\\"Not Applicable\\\".\\n6. Response: I responded with a polite and empathetic message, thanking the reviewer for their feedback and apologizing for any disappointment caused by the poor character development.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_response_parsed\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overall Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Negative\",\n          \"Positive\",\n          \"Neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Writing Style\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Positive\",\n          \"Decent\",\n          \"Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Emotional Impact\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Positive\",\n          \"Mediocre\",\n          \"Neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pacing\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ending\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Response\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Thank you for taking the time to share your thoughts on this book. While it's disappointing to hear that it didn't stand out as remarkable, your feedback is valuable to us. If you have any specific suggestions on what could have improved your experience, we would love to hear them.\",\n          \"Thank you for taking the time to share your feedback. Sorry to hear that you found the book uninspiring and boring. Your input is valuable to us and will be reviewed by our team.\",\n          \"Thank you for taking the time to share your thoughts on this book. We appreciate your feedback and would love to hear more about what could have improved your experience.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":44}],"source":["#Merge\n","data_with_parsed_model_output_4 = pd.concat([data_4, model_response_parsed_df_4], axis=1)\n","data_with_parsed_model_output_4.head(16)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"executionInfo":{"elapsed":121,"status":"ok","timestamp":1751488263144,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"8dewD_2ZU1bZ","outputId":"173f3789-0b92-4d53-a59e-eaf7b7b9a370"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                            CleanedReview Overall Sentiment Writing Style  \\\n","0              Highly disappointing read.          Negative      Negative   \n","1  A page-turner with a powerful message.          Positive      Positive   \n","2          A masterpiece of storytelling.          Positive      Positive   \n","3        Heartwarming and inspiring read.          Positive      Positive   \n","4        Neither good nor bad, just fine.           Neutral       Neutral   \n","\n","  Emotional Impact                        Pacing  \\\n","0         Negative                            []   \n","1         Positive                  [fast-paced]   \n","2         Positive                            []   \n","3         Positive  [heartwarming and inspiring]   \n","4          Neutral                            []   \n","\n","                         Ending  \\\n","0                            []   \n","1                  [satisfying]   \n","2                            []   \n","3  [heartwarming and inspiring]   \n","4                            []   \n","\n","                                            Response  \n","0  Thank you for taking the time to share your fe...  \n","1  Thank you for your review! We're glad you enjo...  \n","2  Thank you for your positive review! We're glad...  \n","3  Thank you for your positive review! We're glad...  \n","4  Thank you for taking the time to share your th...  "],"text/html":["\n","  <div id=\"df-6fe6131e-db6e-4ad2-929d-5703d83888ad\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CleanedReview</th>\n","      <th>Overall Sentiment</th>\n","      <th>Writing Style</th>\n","      <th>Emotional Impact</th>\n","      <th>Pacing</th>\n","      <th>Ending</th>\n","      <th>Response</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Highly disappointing read.</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>Negative</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for taking the time to share your fe...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A page-turner with a powerful message.</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>[fast-paced]</td>\n","      <td>[satisfying]</td>\n","      <td>Thank you for your review! We're glad you enjo...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A masterpiece of storytelling.</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for your positive review! We're glad...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Heartwarming and inspiring read.</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>[heartwarming and inspiring]</td>\n","      <td>[heartwarming and inspiring]</td>\n","      <td>Thank you for your positive review! We're glad...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Neither good nor bad, just fine.</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>Neutral</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>Thank you for taking the time to share your th...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fe6131e-db6e-4ad2-929d-5703d83888ad')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6fe6131e-db6e-4ad2-929d-5703d83888ad button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6fe6131e-db6e-4ad2-929d-5703d83888ad');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-429984f3-676a-4a20-b2d0-50e53ae7c421\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-429984f3-676a-4a20-b2d0-50e53ae7c421')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-429984f3-676a-4a20-b2d0-50e53ae7c421 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"final_data_4","summary":"{\n  \"name\": \"final_data_4\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"CleanedReview\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"A waste of time.\",\n          \"Uninspiring and boring.\",\n          \"Poor character development.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overall Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Negative\",\n          \"Positive\",\n          \"Neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Writing Style\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Positive\",\n          \"Decent\",\n          \"Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Emotional Impact\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Positive\",\n          \"Mediocre\",\n          \"Neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pacing\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ending\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Response\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"Thank you for taking the time to share your thoughts on this book. While it's disappointing to hear that it didn't stand out as remarkable, your feedback is valuable to us. If you have any specific suggestions on what could have improved your experience, we would love to hear them.\",\n          \"Thank you for taking the time to share your feedback. Sorry to hear that you found the book uninspiring and boring. Your input is valuable to us and will be reviewed by our team.\",\n          \"Thank you for taking the time to share your thoughts on this book. We appreciate your feedback and would love to hear more about what could have improved your experience.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":45}],"source":["# Create a final, cleaned dataset by removing raw model output columns\n","final_data_4 = data_with_parsed_model_output_4.drop(['model_response','model_response_parsed', 'ReviewText', 'Sentiment'], axis=1)\n","final_data_4.head()"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1033,"status":"ok","timestamp":1751484536199,"user":{"displayName":"Irina K","userId":"11911088452377057794"},"user_tz":300},"id":"4dC9-YVAXhqF","outputId":"c2f689f5-fe2a-44c4-a2fb-1867a8e39647"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","extended_data.csv saved to Google Drive.\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Save to a specific folder in your Drive\n","final_data_4.to_csv(\"/content/drive/MyDrive/Projects/Generative AI/extended_data.csv\", index=False)\n","print(\"extended_data.csv saved to Google Drive.\")"]},{"cell_type":"code","source":["final_data_4.to_html(\"/content/drive/MyDrive/Projects/Generative AI/extended_data.html\", index=False)\n","print(\"extended_data.html saved to Google Drive.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7VWyQvellBFU","executionInfo":{"status":"ok","timestamp":1751488271252,"user_tz":300,"elapsed":33,"user":{"displayName":"Irina K","userId":"11911088452377057794"}},"outputId":"a9177661-aecd-4069-da8f-6d6adf7b5f88"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["extended_data.html saved to Google Drive.\n"]}]},{"cell_type":"markdown","metadata":{"id":"1ObTyWUVYjCC"},"source":["## LLM-Based Multi Sentiment Analysis Pipeline\n","\n","- Overall Sentiment Detection\n","I started by identifying the overall sentiment of each review using the LLM.\n","\n","- Aspect-Based Sentiment Analysis\n","Next, I extracted sentiment for specific aspects of the book—such as writing style, pacing better understand which elements influenced the reader's opinion.\n","\n","- Liked and Disliked Features\n","I also identified what readers liked or disliked about each aspect, providing more detailed insights (e.g., “engaging writing style,” “rushed ending”).\n","\n","- Automated Customer Response\n","Finally, I generated a personalized response for each review, reflecting the tone and content of the reader's feedback.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t4t4daKKVNyy"},"outputs":[],"source":["from google.colab import auth\n","auth.authenticate_user()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"PzraXPfD7DE6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751483818701,"user_tz":300,"elapsed":3832,"user":{"displayName":"Irina K","userId":"11911088452377057794"}},"outputId":"e4c5832f-0748-4f91-db0d-7c5eb3e4d076"},"outputs":[{"output_type":"stream","name":"stdout","text":["[NbConvertApp] Converting notebook /content/drive/MyDrive/Projects/Generative AI/Book_Review_Analysis_cleaned.ipynb to html\n","/usr/local/share/jupyter/nbconvert/templates/base/display_priority.j2:32: UserWarning: Your element with mimetype(s) dict_keys(['application/vnd.colab-display-data+json']) is not able to be represented.\n","  {%- elif type == 'text/vnd.mermaid' -%}\n","[NbConvertApp] WARNING | Alternative text is missing on 1 image(s).\n","[NbConvertApp] Writing 577953 bytes to /content/drive/MyDrive/Projects/Generative AI/Book_Review_Analysis_cleaned.html\n"]}],"source":["!jupyter nbconvert --to html \"/content/drive/MyDrive/Projects/Generative AI/Book_Review_Analysis_cleaned.ipynb\""]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMNF7bDXXA+PBQgZK8h0N58"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"414889a1ed9d4f55becaffc3812632f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b675d6d6c9048e8b800e3cf0a8e3b98","IPY_MODEL_db8d9f378da847d684e804d801167db9","IPY_MODEL_02f0b9e3b5cf432eb26fd2f51eed4106"],"layout":"IPY_MODEL_d016de8a4e8c447db27b4f69e2c0799c"}},"9b675d6d6c9048e8b800e3cf0a8e3b98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bdc76bea1aa4281b52c06b2cf1aa74f","placeholder":"​","style":"IPY_MODEL_88a11a6743e14d46bf1aa16977d362fe","value":"llama-2-13b-chat.Q5_K_M.gguf: 100%"}},"db8d9f378da847d684e804d801167db9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_144e7aedb94746caa47d3c6c5374a7bc","max":9229924224,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1ee68eb5604457f897d5c13b98ad781","value":9229924224}},"02f0b9e3b5cf432eb26fd2f51eed4106":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8845617b8d5b47cebd108fa9ef0b03a0","placeholder":"​","style":"IPY_MODEL_236a89f46aab412da85afeee1e77c400","value":" 9.23G/9.23G [00:39&lt;00:00, 262MB/s]"}},"d016de8a4e8c447db27b4f69e2c0799c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bdc76bea1aa4281b52c06b2cf1aa74f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88a11a6743e14d46bf1aa16977d362fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"144e7aedb94746caa47d3c6c5374a7bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1ee68eb5604457f897d5c13b98ad781":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8845617b8d5b47cebd108fa9ef0b03a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"236a89f46aab412da85afeee1e77c400":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"780654f355a14e42b0b17ff8f4f4459c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c6cc39262c74be3958843faa5a839a0","IPY_MODEL_c4e2b8c1387542ea9fd4286976bfe3a2","IPY_MODEL_cdf813d832604f8c8d70f7e2d5bacac9"],"layout":"IPY_MODEL_a17f8662096341d5b87415a9fbef2ece"}},"5c6cc39262c74be3958843faa5a839a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abd152c0c1ca414abbb64e05373f89c4","placeholder":"​","style":"IPY_MODEL_d5d2eefd768d4c1cbd6650ee3ab3bcdc","value":"100%"}},"c4e2b8c1387542ea9fd4286976bfe3a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09085677b5b845daa73d5f3da1767b2f","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49663507456349668e1c597cdc4c5c58","value":100}},"cdf813d832604f8c8d70f7e2d5bacac9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9f8e2b2073642b99ecedfe281b18559","placeholder":"​","style":"IPY_MODEL_31a301da77be4c14b2a5282692a9db23","value":" 100/100 [45:00&lt;00:00, 21.18s/it]"}},"a17f8662096341d5b87415a9fbef2ece":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abd152c0c1ca414abbb64e05373f89c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5d2eefd768d4c1cbd6650ee3ab3bcdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09085677b5b845daa73d5f3da1767b2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49663507456349668e1c597cdc4c5c58":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9f8e2b2073642b99ecedfe281b18559":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31a301da77be4c14b2a5282692a9db23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}